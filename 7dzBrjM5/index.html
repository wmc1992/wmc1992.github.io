<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="mingchao.wang">
        <link rel="canonical" href="https://mingchao.wang/005_%E5%B7%A5%E5%85%B7%E6%A1%86%E6%9E%B6/002_lm-evaluation-harness/">
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Index - 算法工程师笔记</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/obsidian.min.css">
        <link href="../../css/extra.css" rel="stylesheet">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-274394082');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="../..">算法工程师笔记</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/wmc1992/" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#lm-evaluation-harness" class="nav-link">lm-evaluation-harness</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#1" class="nav-link">1、安装</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#2" class="nav-link">2、启动命令</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#3" class="nav-link">3、完整参数</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#4" class="nav-link">4、输出</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#5" class="nav-link">5、不同模型所需要的特殊操作</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#51-openllama" class="nav-link">5.1 openllama 模型</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#52-llama-hf" class="nav-link">5.2 llama-hf 模型</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#6" class="nav-link">6、一些模型的测试结果记录</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#61-llama-7b" class="nav-link">6.1 模型LLaMA-7B</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#62-open_llama_7b" class="nav-link">6.2 模型open_llama_7b</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#63-dolly-v2-12b" class="nav-link">6.3 模型dolly-v2-12b</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#reference" class="nav-link">Reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p align="right">[<a href="/7dzBrjM5_no_toc/">隐藏左侧目录栏</a>][<a href="/7dzBrjM5/">显示左侧目录栏</a>]</p>

<h1 id="lm-evaluation-harness">lm-evaluation-harness<a class="headerlink" href="#lm-evaluation-harness" title="Permanent link">#</a></h1>
<blockquote>
<p>项目地址：<a href="https://github.com/EleutherAI/lm-evaluation-harness">https://github.com/EleutherAI/lm-evaluation-harness</a></p>
</blockquote>
<p>该项目提供了一个统一的框架来测试大量不同评估任务的生成语言模型。</p>
<p>该项目的功能有：</p>
<ul>
<li>已实施 200 多个 task。请参阅 <a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/master/docs/task_table.md">task-table</a> 以获取完整task列表。</li>
<li>支持通过 <a href="https://github.com/huggingface/transformers">huggingface/transformers</a> 、<a href="https://github.com/EleutherAI/gpt-neox">EleutherAI/gpt-neox</a>、<a href="https://github.com/microsoft/Megatron-DeepSpeed/">microsoft/Megatron-DeepSpeed</a> 进行模型加载。</li>
<li>支持商业 API，包括OpenAI、goose.ai和TextSynth。</li>
<li>支持对 HuggingFace 的 PEFT 库中支持的适配器（例如 LoRa）进行评估。</li>
<li>使用公开的提示进行评估可确保论文之间的可重复性和可比性。</li>
<li>任务版本控制可确保任务更新时的可重复性。</li>
</ul>
<h2 id="1">1、安装<a class="headerlink" href="#1" title="Permanent link">#</a></h2>
<p>直接按照该项目的 README.md 中介绍的进行安装就行，比较简单，如下：</p>
<pre><code>git clone https://github.com/EleutherAI/lm-evaluation-harness
cd lm-evaluation-harness
pip install -e .
</code></pre>
<h2 id="2">2、启动命令<a class="headerlink" href="#2" title="Permanent link">#</a></h2>
<p>最简单的评估命令如下所示，其中使用到的参数说明如下：</p>
<ul>
<li><code>model</code>：指的是模型推理的类型；</li>
<li><code>model_args</code>：是模型的参数，必须要指定的 <code>pretrained</code> 是模型的命令或本地路径，还可以指定模型的其他参数，比如 <code>dtype="float"</code>，多个参数之间使用英文逗号分隔；</li>
<li><code>tasks</code>：数据集名称，多个数据集之间使用英文逗号分隔；</li>
<li><code>device</code>：预测时使用的设备；</li>
</ul>
<pre><code>python main.py \
    --model hf-causal \
    --model_args pretrained=openlm-research/open_llama_13b \
    --tasks hellaswag,boolq \
    --device cuda:0
</code></pre>
<p>模型文件可以使用本地路径，如下述例子：</p>
<pre><code>python main.py \
    --model hf-causal \
    --model_args pretrained=/data/pretrained_models/open_llama_7b \
    --tasks hellaswag,boolq \
    --device cuda:0
</code></pre>
<blockquote>
<p>在该项目中，所有的数据集不支持指定本地路径，而是在程序里自动从 huggingface hub 中下载的，那么在国内就有一个很常见的问题：网络问题。一般需要科学上网才能下载下来。</p>
</blockquote>
<h2 id="3">3、完整参数<a class="headerlink" href="#3" title="Permanent link">#</a></h2>
<p>执行命令 <code>python main.py --help</code> 可得如下所有可传入的参数：</p>
<pre><code>usage: main.py [-h] --model MODEL [--model_args MODEL_ARGS]
               [--tasks {anagrams1,anagrams2,anli_r1,...}]
               [--provide_description] [--num_fewshot NUM_FEWSHOT] [--batch_size BATCH_SIZE] [--max_batch_size MAX_BATCH_SIZE] [--device DEVICE] [--output_path OUTPUT_PATH] [--limit LIMIT]
               [--data_sampling DATA_SAMPLING] [--no_cache] [--decontamination_ngrams_path DECONTAMINATION_NGRAMS_PATH] [--description_dict_path DESCRIPTION_DICT_PATH] [--check_integrity] [--write_out]
               [--output_base_path OUTPUT_BASE_PATH]

options:
  -h, --help            show this help message and exit
  --model MODEL
  --model_args MODEL_ARGS
  --tasks {anagrams1,anagrams2,anli_r1,...}
  --provide_description
  --num_fewshot NUM_FEWSHOT
  --batch_size BATCH_SIZE
  --max_batch_size MAX_BATCH_SIZE
                        Maximal batch size to try with --batch_size auto
  --device DEVICE
  --output_path OUTPUT_PATH
  --limit LIMIT         Limit the number of examples per task. If &lt;1, limit is a percentage of the total number of examples.
  --data_sampling DATA_SAMPLING
  --no_cache
  --decontamination_ngrams_path DECONTAMINATION_NGRAMS_PATH
  --description_dict_path DESCRIPTION_DICT_PATH
  --check_integrity
  --write_out
  --output_base_path OUTPUT_BASE_PATH
</code></pre>
<h2 id="4">4、输出<a class="headerlink" href="#4" title="Permanent link">#</a></h2>
<p>评估完成后的输出结果如下所示：</p>
<pre><code>|    Task     |Version| Metric |Value |   |Stderr|
|-------------|------:|--------|-----:|---|-----:|
|hellaswag    |      0|acc     |0.5035|±  |0.0050|
|             |       |acc_norm|0.6471|±  |0.0048|
|arc_challenge|      0|acc     |0.3635|±  |0.0141|
|             |       |acc_norm|0.3712|±  |0.0141|
</code></pre>
<p>这是一个markdown中表格的语法，直接贴到本文中，得到的表格如下：</p>
<table>
<thead>
<tr>
<th>Task</th>
<th align="right">Version</th>
<th>Metric</th>
<th align="right">Value</th>
<th></th>
<th align="right">Stderr</th>
</tr>
</thead>
<tbody>
<tr>
<td>hellaswag</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.5035</td>
<td>±</td>
<td align="right">0.0050</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.6471</td>
<td>±</td>
<td align="right">0.0048</td>
</tr>
<tr>
<td>arc_challenge</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3635</td>
<td>±</td>
<td align="right">0.0141</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.3712</td>
<td>±</td>
<td align="right">0.0141</td>
</tr>
</tbody>
</table>
<h2 id="5">5、不同模型所需要的特殊操作<a class="headerlink" href="#5" title="Permanent link">#</a></h2>
<h3 id="51-openllama">5.1 openllama 模型<a class="headerlink" href="#51-openllama" title="Permanent link">#</a></h3>
<blockquote>
<p>模型项目链接: <a href="https://github.com/openlm-research/open_llama">https://github.com/openlm-research/open_llama</a></p>
</blockquote>
<p>openllama这个模型在使用 huggingface 的 FastTokenizer 时会出现错误，所以无论是使用 openllama 模型进行推理，还是对该模型进行评估，都不能够使用 FastTokenizer，需要禁用 FastTokenizer。</p>
<p>如果是推理的话以下两种方式都可以避免使用 FastTokenizer：</p>
<pre><code class="language-python">from transformers import LlamaTokenizer

model_path = 'openlm-research/open_llama_13b'
tokenizer = LlamaTokenizer.from_pretrained(model_path)  # 这里直接使用 LlamaTokenizer 
</code></pre>
<pre><code class="language-python">from transformers import AutoTokenizer

model_path = 'openlm-research/open_llama_13b'
tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)  # 使用 AutoTokenizer 时要加上参数 use_fast=False
</code></pre>
<p>在使用该项目进行评估时，为了禁用 FastTokenizer 则需要修改一下代码，需要修改这部分代码片段：<a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/4b701e228768052cfae9043dca13e82052ca5eea/lm_eval/models/huggingface.py#LL313C9-L316C10">lm-eval-harness 代码片段</a>，加上参数 <code>use_fast=False</code> 即可：</p>
<pre><code class="language-python">tokenizer = self.AUTO_TOKENIZER_CLASS.from_pretrained(
    pretrained if tokenizer is None else tokenizer,
    revision=revision + (&quot;/&quot; + subfolder if subfolder is not None else &quot;&quot;),
    use_fast=False
)
</code></pre>
<h3 id="52-llama-hf">5.2 llama-hf 模型<a class="headerlink" href="#52-llama-hf" title="Permanent link">#</a></h3>
<p>使用该模型时也会报错，这个报错的原因是项目 <a href="https://github.com/huggingface/transformers">huggingface/transformers</a> 中实现的 llama 模型的代码和配置文件对应不上引起的问题，使用 AutoModel 和 AutoTokenizer 无法正确的载入模型。需要修改为使用 LlamaForCausalLM 和 LlamaTokenizer 加载模型。该问题的详细描述见 <a href="https://github.com/huggingface/transformers/issues/22222#issuecomment-1473423183">ValueError: Tokenizer class LLaMATokenizer does not exist or is not currently imported.</a></p>
<p>需要修改的代码片段为 <a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/master/lm_eval/models/gpt2.py#L85">lm-eval-harness 代码片段</a>。</p>
<p>原来的代码为：</p>
<pre><code class="language-python">    # Initialize new model and tokenizer instances
    self.model = transformers.AutoModelForCausalLM.from_pretrained(
            pretrained,
            load_in_8bit=load_in_8bit,
            low_cpu_mem_usage=low_cpu_mem_usage,
            revision=revision,
            torch_dtype=_get_dtype(dtype),
            trust_remote_code=trust_remote_code,
            ).to(self.device)
    self.tokenizer = transformers.AutoTokenizer.from_pretrained(
            tokenizer if tokenizer else pretrained,
            revision=revision,
            trust_remote_code=trust_remote_code,
            )
</code></pre>
<p>需要修改成：</p>
<pre><code class="language-python">    # Initialize new model and tokenizer instances
    self.model = transformers.LlamaForCausalLM.from_pretrained(
            pretrained,
            load_in_8bit=load_in_8bit,
            low_cpu_mem_usage=low_cpu_mem_usage,
            revision=revision,
            torch_dtype=_get_dtype(dtype),
            trust_remote_code=trust_remote_code,
            ).to(self.device)
    self.tokenizer = transformers.LlamaTokenizer.from_pretrained(
            tokenizer if tokenizer else pretrained,
            revision=revision,
            trust_remote_code=trust_remote_code,
            )
</code></pre>
<p>修改完上述代码之后用正常的方式对 llama-hf 进行评估就可以了。</p>
<h2 id="6">6、一些模型的测试结果记录<a class="headerlink" href="#6" title="Permanent link">#</a></h2>
<h3 id="61-llama-7b">6.1 模型LLaMA-7B<a class="headerlink" href="#61-llama-7b" title="Permanent link">#</a></h3>
<table>
<thead>
<tr>
<th>Task</th>
<th align="right">Version</th>
<th>Metric</th>
<th align="right">Value</th>
<th></th>
<th align="right">Stderr</th>
</tr>
</thead>
<tbody>
<tr>
<td>anli_r1</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3510</td>
<td>±</td>
<td align="right">0.0151</td>
</tr>
<tr>
<td>anli_r2</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3620</td>
<td>±</td>
<td align="right">0.0152</td>
</tr>
<tr>
<td>anli_r3</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3967</td>
<td>±</td>
<td align="right">0.0141</td>
</tr>
<tr>
<td>arc_challenge</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.4189</td>
<td>±</td>
<td align="right">0.0144</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.4471</td>
<td>±</td>
<td align="right">0.0145</td>
</tr>
<tr>
<td>arc_easy</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.7534</td>
<td>±</td>
<td align="right">0.0088</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.7281</td>
<td>±</td>
<td align="right">0.0091</td>
</tr>
<tr>
<td>boolq</td>
<td align="right">1</td>
<td>acc</td>
<td align="right">0.7505</td>
<td>±</td>
<td align="right">0.0076</td>
</tr>
<tr>
<td>hellaswag</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.5692</td>
<td>±</td>
<td align="right">0.0049</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.7618</td>
<td>±</td>
<td align="right">0.0043</td>
</tr>
<tr>
<td>openbookqa</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3440</td>
<td>±</td>
<td align="right">0.0213</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.4440</td>
<td>±</td>
<td align="right">0.0222</td>
</tr>
<tr>
<td>piqa</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.7867</td>
<td>±</td>
<td align="right">0.0096</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.7916</td>
<td>±</td>
<td align="right">0.0095</td>
</tr>
<tr>
<td>record</td>
<td align="right">0</td>
<td>f1</td>
<td align="right">0.9130</td>
<td>±</td>
<td align="right">0.0028</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>em</td>
<td align="right">0.9057</td>
<td>±</td>
<td align="right">0.0029</td>
</tr>
<tr>
<td>rte</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.6643</td>
<td>±</td>
<td align="right">0.0284</td>
</tr>
<tr>
<td>truthfulqa_mc</td>
<td align="right">1</td>
<td>mc1</td>
<td align="right">0.2191</td>
<td>±</td>
<td align="right">0.0145</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>mc2</td>
<td align="right">0.3408</td>
<td>±</td>
<td align="right">0.0131</td>
</tr>
<tr>
<td>wic</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.4890</td>
<td>±</td>
<td align="right">0.0198</td>
</tr>
<tr>
<td>winogrande</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.6993</td>
<td>±</td>
<td align="right">0.0129</td>
</tr>
</tbody>
</table>
<h3 id="62-open_llama_7b">6.2 模型open_llama_7b<a class="headerlink" href="#62-open_llama_7b" title="Permanent link">#</a></h3>
<table>
<thead>
<tr>
<th>Task</th>
<th align="right">Version</th>
<th>Metric</th>
<th align="right">Value</th>
<th></th>
<th align="right">Stderr</th>
</tr>
</thead>
<tbody>
<tr>
<td>anli_r1</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3150</td>
<td>±</td>
<td align="right">0.0147</td>
</tr>
<tr>
<td>anli_r2</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3530</td>
<td>±</td>
<td align="right">0.0151</td>
</tr>
<tr>
<td>anli_r3</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3683</td>
<td>±</td>
<td align="right">0.0139</td>
</tr>
<tr>
<td>arc_challenge</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3635</td>
<td>±</td>
<td align="right">0.0141</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.3712</td>
<td>±</td>
<td align="right">0.0141</td>
</tr>
<tr>
<td>arc_easy</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.6957</td>
<td>±</td>
<td align="right">0.0094</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.6713</td>
<td>±</td>
<td align="right">0.0096</td>
</tr>
<tr>
<td>boolq</td>
<td align="right">1</td>
<td>acc</td>
<td align="right">0.7049</td>
<td>±</td>
<td align="right">0.0080</td>
</tr>
<tr>
<td>hellaswag</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.5035</td>
<td>±</td>
<td align="right">0.0050</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.6471</td>
<td>±</td>
<td align="right">0.0048</td>
</tr>
<tr>
<td>openbookqa</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3020</td>
<td>±</td>
<td align="right">0.0206</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.4000</td>
<td>±</td>
<td align="right">0.0219</td>
</tr>
<tr>
<td>piqa</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.7470</td>
<td>±</td>
<td align="right">0.0101</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.7448</td>
<td>±</td>
<td align="right">0.0102</td>
</tr>
<tr>
<td>record</td>
<td align="right">0</td>
<td>f1</td>
<td align="right">0.9023</td>
<td>±</td>
<td align="right">0.0029</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>em</td>
<td align="right">0.8944</td>
<td>±</td>
<td align="right">0.0031</td>
</tr>
<tr>
<td>rte</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.6101</td>
<td>±</td>
<td align="right">0.0294</td>
</tr>
<tr>
<td>truthfulqa_mc</td>
<td align="right">1</td>
<td>mc1</td>
<td align="right">0.2313</td>
<td>±</td>
<td align="right">0.0148</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>mc2</td>
<td align="right">0.3545</td>
<td>±</td>
<td align="right">0.0136</td>
</tr>
<tr>
<td>wic</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.4875</td>
<td>±</td>
<td align="right">0.0198</td>
</tr>
<tr>
<td>winogrande</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.6677</td>
<td>±</td>
<td align="right">0.0132</td>
</tr>
</tbody>
</table>
<h3 id="63-dolly-v2-12b">6.3 模型dolly-v2-12b<a class="headerlink" href="#63-dolly-v2-12b" title="Permanent link">#</a></h3>
<table>
<thead>
<tr>
<th>Task</th>
<th align="right">Version</th>
<th>Metric</th>
<th align="right">Value</th>
<th></th>
<th align="right">Stderr</th>
</tr>
</thead>
<tbody>
<tr>
<td>anli_r1</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3290</td>
<td>±</td>
<td align="right">0.0149</td>
</tr>
<tr>
<td>anli_r2</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3440</td>
<td>±</td>
<td align="right">0.0150</td>
</tr>
<tr>
<td>anli_r3</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3650</td>
<td>±</td>
<td align="right">0.0139</td>
</tr>
<tr>
<td>arc_challenge</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3643</td>
<td>±</td>
<td align="right">0.0141</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.3746</td>
<td>±</td>
<td align="right">0.0141</td>
</tr>
<tr>
<td>arc_easy</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.6742</td>
<td>±</td>
<td align="right">0.0096</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.6427</td>
<td>±</td>
<td align="right">0.0098</td>
</tr>
<tr>
<td>boolq</td>
<td align="right">1</td>
<td>acc</td>
<td align="right">0.5697</td>
<td>±</td>
<td align="right">0.0087</td>
</tr>
<tr>
<td>hellaswag</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.5422</td>
<td>±</td>
<td align="right">0.0050</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.7088</td>
<td>±</td>
<td align="right">0.0045</td>
</tr>
<tr>
<td>openbookqa</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.3000</td>
<td>±</td>
<td align="right">0.0205</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.4000</td>
<td>±</td>
<td align="right">0.0219</td>
</tr>
<tr>
<td>piqa</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.7465</td>
<td>±</td>
<td align="right">0.0102</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>acc_norm</td>
<td align="right">0.7584</td>
<td>±</td>
<td align="right">0.0100</td>
</tr>
<tr>
<td>record</td>
<td align="right">0</td>
<td>f1</td>
<td align="right">0.7893</td>
<td>±</td>
<td align="right">0.0040</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>em</td>
<td align="right">0.7816</td>
<td>±</td>
<td align="right">0.0041</td>
</tr>
<tr>
<td>rte</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.5668</td>
<td>±</td>
<td align="right">0.0298</td>
</tr>
<tr>
<td>truthfulqa_mc</td>
<td align="right">1</td>
<td>mc1</td>
<td align="right">0.2007</td>
<td>±</td>
<td align="right">0.0140</td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td>mc2</td>
<td align="right">0.3337</td>
<td>±</td>
<td align="right">0.0148</td>
</tr>
<tr>
<td>wic</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.4906</td>
<td>±</td>
<td align="right">0.0198</td>
</tr>
<tr>
<td>winogrande</td>
<td align="right">0</td>
<td>acc</td>
<td align="right">0.6148</td>
<td>±</td>
<td align="right">0.0137</td>
</tr>
</tbody>
</table>
<h2 id="reference">Reference<a class="headerlink" href="#reference" title="Permanent link">#</a></h2>
<ul>
<li>
<p><a href="https://github.com/EleutherAI/lm-evaluation-harness">https://github.com/EleutherAI/lm-evaluation-harness</a></p>
</li>
<li>
<p><a href="https://github.com/openlm-research/open_llama">https://github.com/openlm-research/open_llama</a></p>
</li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2021 Microsoft Research;<a href="https://beian.miit.gov.cn/">备案号：京ICP备2022025323号-1</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../mathjax-config.js" defer></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
