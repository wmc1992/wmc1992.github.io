<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="mingchao.wang">
        <link rel="canonical" href="https://mingchao.wang/006_LLM/997_%E9%9B%B6%E6%95%A3%E7%9F%A5%E8%AF%86%E7%82%B9/">
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Index - 算法工程师笔记</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/obsidian.min.css">
        <link href="../../css/extra.css" rel="stylesheet">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-274394082');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="../..">算法工程师笔记</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/wmc1992/" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#llm" class="nav-link">LLM零散知识点</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#1" class="nav-link">1、多轮对话如何训练</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#1_1" class="nav-link">训练方式1</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#2" class="nav-link">训练方式2</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#_1" class="nav-link">两种方式对比</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#2llamacheckpoint" class="nav-link">2、llama不同checkpoint的区别</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p align="right">[<a href="/0fCSD2lI_no_toc/">隐藏左侧目录栏</a>][<a href="/0fCSD2lI/">显示左侧目录栏</a>]</p>

<h1 id="llm">LLM零散知识点<a class="headerlink" href="#llm" title="Permanent link">#</a></h1>
<h2 id="1">1、多轮对话如何训练<a class="headerlink" href="#1" title="Permanent link">#</a></h2>
<p>多轮对话数据一般为如下形式：</p>
<pre><code>{&quot;user&quot;: &quot;问：aaa&quot;, &quot;assistant&quot;: &quot;答：xxx&quot;, &quot;user&quot;: &quot;问：bbb&quot;, &quot;assistant&quot;: &quot;答：yyy&quot;, &quot;user&quot;: &quot;问：ccc&quot;, &quot;assistant&quot;: &quot;答：zzz&quot;}
</code></pre>
<p>可以简单记为 Q1 A1 Q2 A2 Q3 A3。</p>
<h3 id="1_1">训练方式1<a class="headerlink" href="#1_1" title="Permanent link">#</a></h3>
<p>一般来说对上述这条数据会构造成如下三条训练数据：</p>
<ul>
<li>Q1 --&gt; A1</li>
<li>Q1 A1 Q2 --&gt; A2</li>
<li>Q1 A1 Q2 A2 Q3 --&gt; A3</li>
</ul>
<p>在这种训练方式下，一个session变成了三条数据，并且上文有依次重复的情况，数据中大部分都是pad token，训练数据利用效率低下。另外会有数据重复膨胀的问题，训练数据重复膨胀为 session数量*平均轮次数。由于上文有重复部分，训练效率也会低下。</p>
<h3 id="2">训练方式2<a class="headerlink" href="#2" title="Permanent link">#</a></h3>
<p>不将一个session变成多条数据，而是仅作为一条数据。而是把所有的answer都作为待预测的标签。</p>
<p>模型的输入文本为：Q1 A1 Q2 A2 Q3 A3</p>
<p>构造要学习的label时，所有的question中的token都是-100，即不计算loss，所有的answer都计算loss。即对于该条输入文本，模型需要学习 A1、A2、A3 这个间断的三部分。很明显的可以看出，这已经不再是纯粹的 decoder-only 模型了。</p>
<h3 id="_1">两种方式对比<a class="headerlink" href="#_1" title="Permanent link">#</a></h3>
<ul>
<li>
<p>训练方式2的总数据量会明显小于训练方式1；</p>
</li>
<li>
<p>关于每次对话对总损失的影响占比：训练方式2的同一session不同轮次产生的loss是求平均的，训练方式1同一session不同轮次产生的loss是求和的，这样会影响不同轮次在loss中的权重的分配，另外还会影响norm的计算。</p>
<p>用一个简化地例子定量分析下，我们假设两条训练样本分为：</p>
<p>数据1: "问: A 答: xx"
数据2: "问: A 答: xx 问: B 答: xx 问: C 答: xx"</p>
<p>则训练方式2中每个轮次对loss的权重为 (Data1a + (Data2a + Data2b + Data2c)/3 )/2。这两条数据，轮次A，轮次B，轮次C 的权重分别为：2/3、1/6、1/6。</p>
<p>训练方式1中每个轮次对loss的权重为 (Data1a + Data2a + (Dat2a + Data2b)/2 +(Data2a + Data2b + Data2c)/3)/4。这两条数据 轮次A，轮次B，轮次C 的权重分别为，17/24、5/24、1/12。</p>
<p>从上述的权重分布来看，训练方式2中靠后的轮次的权重要比训练方式1要大一些，这种结果是合理的，因为大部分场景下，开场白是趋同或重复的。</p>
</li>
<li>
<p>训练方式2相比于训练方式1有一个非常明显的缺陷是：在训练阶段，模型看到的信息是不全的，在预测 A2 时并不能看到 A1 的信息，在预测 A3 时也不能看到 A1和A2 的信息，这在多轮对话中是比较明显有问题的。</p>
</li>
<li>
<p>从形式上，训练方式2并不是 "给一个问题，预测一个输出" 的形式，这种训练方式在使用时效果如何未知。</p>
</li>
</ul>
<h2 id="2llamacheckpoint">2、llama不同checkpoint的区别<a class="headerlink" href="#2llamacheckpoint" title="Permanent link">#</a></h2>
<p>这里主要是记录一下通过下述两种方式获取到的模型，在使用时的区别：</p>
<ul>
<li>
<p>使用 huggingface 的 transformers 中的代码 <a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert_llama_weights_to_hf.py">convert_llama_weights_to_hf</a> 对原始的meta放出来的模型转换得到的模型文件。为了方便描述，把这个叫做convert版模型；</p>
</li>
<li>
<p>从 huggingface model hub 中下载的已经转化好的模型文件，比如7B的模型文件为："decapoda-research/llama-7b-hf"。为了方便描述，把这个叫做decapoda-research版模型。</p>
</li>
</ul>
<p>主要的区别在模型的config文件上，convert版模型的配置文件 <code>config.json</code> 如下所示：</p>
<pre><code class="language-json">{
    &quot;architectures&quot;: [
      &quot;LlamaForCausalLM&quot;
    ],
    &quot;bos_token_id&quot;: 1,
    &quot;eos_token_id&quot;: 2,
    &quot;pad_token_id&quot;: 0,
    &quot;hidden_act&quot;: &quot;silu&quot;,
    &quot;hidden_size&quot;: 4096,
    &quot;initializer_range&quot;: 0.02,
    &quot;intermediate_size&quot;: 11008,
    &quot;max_position_embeddings&quot;: 2048,
    &quot;model_type&quot;: &quot;llama&quot;,
    &quot;num_attention_heads&quot;: 32,
    &quot;num_hidden_layers&quot;: 32,
    &quot;rms_norm_eps&quot;: 1e-06,
    &quot;rope_scaling&quot;: null,
    &quot;tie_word_embeddings&quot;: false,
    &quot;torch_dtype&quot;: &quot;float16&quot;,
    &quot;transformers_version&quot;: &quot;4.31.0.dev0&quot;,
    &quot;use_cache&quot;: true,
    &quot;vocab_size&quot;: 32000
}
</code></pre>
<p>decapoda-research版模型的配置文件 <code>config.json</code> 如下所示： </p>
<pre><code class="language-json">{
    &quot;architectures&quot;: [
        &quot;LLaMAForCausalLM&quot;
    ],
    &quot;bos_token_id&quot;: 0,
    &quot;eos_token_id&quot;: 1,
    &quot;pad_token_id&quot;: -1,
    &quot;hidden_act&quot;: &quot;silu&quot;,
    &quot;hidden_size&quot;: 4096,
    &quot;initializer_range&quot;: 0.02,
    &quot;intermediate_size&quot;: 11008,
    &quot;max_sequence_length&quot;: 2048,
    &quot;model_type&quot;: &quot;llama&quot;,
    &quot;num_attention_heads&quot;: 32,
    &quot;num_hidden_layers&quot;: 32,
    &quot;rms_norm_eps&quot;: 1e-06,
    &quot;torch_dtype&quot;: &quot;float16&quot;,
    &quot;transformers_version&quot;: &quot;4.27.0.dev0&quot;,
    &quot;use_cache&quot;: true,
    &quot;vocab_size&quot;: 32000
}
</code></pre>
<p>可以看出 "bos_token_id"、"eos_token_id"、"pad_token_id" 这三个特殊的token在两个模型中是完全不同的。下面看一下llama的32000个vocab对应的字典，如下所示：</p>
<pre><code>{
  &quot;&lt;unk&gt;&quot;: 0,
  &quot;&lt;s&gt;&quot;: 1,
  &quot;&lt;/s&gt;&quot;: 2,
  &quot;&lt;0x00&gt;&quot;: 3,
  &quot;&lt;0x01&gt;&quot;: 4,
  ... ...
  &quot;收&quot;: 31997,
  &quot;弘&quot;: 31998,
  &quot;给&quot;: 31999,
}
</code></pre>
<p>可以看出将 "bos_token_id"、"eos_token_id" 分别设置为 1 和 2 比较合适。至于 "pad_token_id" 设置为 -1 虽然也没有问题，但还是推荐设置为 0。因为不同的代码中对 "pad_token_id" 的处理方式不一致，将其设置为 0 可以避免出现问题。比如在 QLoRA 的官方代码中，如果配置文件里的 "pad_token_id" 设置为 -1 了，那么运行时就会出现很离谱的bug。</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2021 Microsoft Research;<a href="https://beian.miit.gov.cn/">备案号：京ICP备2022025323号-1</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../mathjax-config.js" defer></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
