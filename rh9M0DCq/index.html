<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="mingchao.wang">
        <link rel="canonical" href="https://mingchao.wang/003_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/005_Normalize/prenorm_vs_postnorm/">
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>Index - 算法工程师笔记</title>
        <link href="../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/obsidian.min.css">
        <link href="../../../css/extra.css" rel="stylesheet">

        <script src="../../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-274394082');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="../../..">算法工程师笔记</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/wmc1992/" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#pre-norm-post-norm" class="nav-link">Pre Norm 与 Post Norm</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#1" class="nav-link">1、公式</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#2" class="nav-link">2、实验中观察到的现象</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#3-normalize" class="nav-link">3、残差连接与 Normalize 的联系</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#4post-norm" class="nav-link">4、Post Norm</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#5pre-norm" class="nav-link">5、Pre Norm</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#6" class="nav-link">6、两者对比</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#reference" class="nav-link">Reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p align="right">[<a href="/rh9M0DCq_no_toc/">隐藏左侧目录栏</a>][<a href="/rh9M0DCq/">显示左侧目录栏</a>]</p>

<h1 id="pre-norm-post-norm">Pre Norm 与 Post Norm<a class="headerlink" href="#pre-norm-post-norm" title="Permanent link">#</a></h1>
<h2 id="1">1、公式<a class="headerlink" href="#1" title="Permanent link">#</a></h2>
<p>Post Norm 的公式：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}x_{t+1} = \text{Norm}(x_t + F_t(x_t))\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}x_{t+1} = \text{Norm}(x_t + F_t(x_t))\end{equation}</script>
</div>
<p>Pre Norm 的公式：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}x_{t+1} = x_t + F_t(\text{Norm}(x_t))\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}x_{t+1} = x_t + F_t(\text{Norm}(x_t))\end{equation}</script>
</div>
<h2 id="2">2、实验中观察到的现象<a class="headerlink" href="#2" title="Permanent link">#</a></h2>
<p>这是一个总共12层，有125M参数的模型。下图展示的是在模型训练的早期（可以看出step都是小于600的），第0层、第1层、第6层、第10层、第11层的梯度的平均L1范数值。</p>
<p>可以看出，使用 Post Norm 时，第0层和第1层的梯度较小，第10层和第11层的梯度较大。也就是靠前的层梯度较小，靠后的层梯度较大。并且有其他研究表明，靠前层的梯度还会随着训练的进行还会迅速减小，导致靠前的层之后就得不到充分的训练。</p>
<p>使用 Pre Norm 时，第0层和第1层的梯度较大，第10层和第11层的梯度较小。也就是靠前的层梯度较大，靠后的层梯度较小。</p>
<p>就理想情况来说，无论是"靠前层梯度小靠后层梯度大"，还是"靠前层梯度大靠后层梯度小"，都不是想要的，最想要的是：每一层的梯度是相同的（这里不是说梯度完全相同，而是梯度的统计值相同，比如每层梯度的L1范数值相同）。做这方面的工作有很多，比如 <a href="https://arxiv.org/pdf/2110.09456.pdf">NormFormer</a> 是在 Pre Norm 的基础上做优化，通过缓解 "靠前层梯度大靠后层梯度小" 的问题达到每层梯度相同；<a href="https://arxiv.org/pdf/2203.00555.pdf">DeepNet</a> 是在 Post Norm 的基础上做优化，通过缓解 "靠前层梯度小靠后层梯度大" 的问题达到每层梯度相同；</p>
<p><img alt="" src="/rh9M0DCq/assets/prenorm_vs_postnorm_01.png" /></p>
<p>上述现象出自论文: <a href="https://arxiv.org/pdf/2110.09456.pdf">NormFormer: Improved Transformer Pretraining with Extra Normalization</a></p>
<p>上面是从实验中观察到的现象，下面从理论方面分析一下产生该现象的原因。</p>
<h2 id="3-normalize">3、残差连接与 Normalize 的联系<a class="headerlink" href="#3-normalize" title="Permanent link">#</a></h2>
<p>残差连接这种设计的思路是给比较靠前面的层一条绿色通道，反向传播时梯度可以沿着这条绿色通道直接传递到比较靠前面的层，其前向传播的公式为：<span class="arithmatex"><span class="MathJax_Preview">x + F(x)</span><script type="math/tex">x + F(x)</script></span>。</p>
<p>记随机变量 <span class="arithmatex"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> 的方差为 <span class="arithmatex"><span class="MathJax_Preview">\sigma_1^2</span><script type="math/tex">\sigma_1^2</script></span>，记随机变量 <span class="arithmatex"><span class="MathJax_Preview">F(x)</span><script type="math/tex">F(x)</script></span> 的方差为 <span class="arithmatex"><span class="MathJax_Preview">\sigma_2^2</span><script type="math/tex">\sigma_2^2</script></span>，并且假设这两个随机变量是相互独立的，那么有随机变量 <span class="arithmatex"><span class="MathJax_Preview">x+F(x)</span><script type="math/tex">x+F(x)</script></span> 的方差为 <span class="arithmatex"><span class="MathJax_Preview">\sigma_1^2+\sigma_2^2</span><script type="math/tex">\sigma_1^2+\sigma_2^2</script></span>。</p>
<blockquote>
<p>这里利用了方差的性质：如果 <span class="arithmatex"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>、<span class="arithmatex"><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span> 是独立的随机变量，那么有 <span class="arithmatex"><span class="MathJax_Preview">\text{Var}(x+y) = \text{Var}(x) + \text{Var}(y)</span><script type="math/tex">\text{Var}(x+y) = \text{Var}(x) + \text{Var}(y)</script></span>。</p>
<p>更多方差的性质见: <a href="https://zhuanlan.zhihu.com/p/161505873">https://zhuanlan.zhihu.com/p/161505873</a></p>
</blockquote>
<p>可以看出，由于方差本身必然是非负的，在残差连接的结构设计下，随着层数的加深，方差是越来越大的，所以需要有一个策略控制方差在一定的范围内。而 normalize 就是能够控制方差很好的一种方法，下面分别分析 Pre Norm 和 Post Norm 在控制方差方面的效果，以及各自自身的缺陷。</p>
<h2 id="4post-norm">4、Post Norm<a class="headerlink" href="#4post-norm" title="Permanent link">#</a></h2>
<p>Post Norm 的公式为 <span class="arithmatex"><span class="MathJax_Preview">x_{t+1} = \text{Norm}(x_t + F_t(x_t))</span><script type="math/tex">x_{t+1} = \text{Norm}(x_t + F_t(x_t))</script></span></p>
<p>在对其分析之前，假设初始状态下 <span class="arithmatex"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> 与 <span class="arithmatex"><span class="MathJax_Preview">F(x)</span><script type="math/tex">F(x)</script></span> 的方差都是1，所以此时 <span class="arithmatex"><span class="MathJax_Preview">x+F(x)</span><script type="math/tex">x+F(x)</script></span> 的方差为2。经过 Post Norm 之后 <span class="arithmatex"><span class="MathJax_Preview">x+F(x)</span><script type="math/tex">x+F(x)</script></span> 的方差又变为了1。</p>
<p>也就是说对 <span class="arithmatex"><span class="MathJax_Preview">x+F(x)</span><script type="math/tex">x+F(x)</script></span> 做 Norm 等同于对 <span class="arithmatex"><span class="MathJax_Preview">x+F(x)</span><script type="math/tex">x+F(x)</script></span> 除以 <span class="arithmatex"><span class="MathJax_Preview">\sqrt{2}</span><script type="math/tex">\sqrt{2}</script></span>，如下公式所示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}x_{t+1} = \text{Norm}(x_t + F_t(x_t)) \rightarrow \frac{x_t+F_t(x_t)}{\sqrt{2}}\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}x_{t+1} = \text{Norm}(x_t + F_t(x_t)) \rightarrow \frac{x_t+F_t(x_t)}{\sqrt{2}}\end{equation}</script>
</div>
<p>基于上述公式，一直递归下去，公式如下所示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}\begin{split}
x_{t+1} &amp;= \frac{x_t + F_t(x_t)}{\sqrt{2}} \\
&amp;= \frac{x_t}{2^{1/2}} + \frac{F_t(x_t)}{2^{1/2}} \\
&amp; = \frac{x_{t-1}}{2^{2/2}} + \frac{F_{t-1}(x_{t-1})}{2^{2/2}} + \frac{F_t(x_t)}{2^{1/2}} \\
&amp;= \frac{x_{t-2}}{2^{3/2}} + \frac{F_{t-2}(x_{t-2})}{2^{3/2}} + \frac{F_{t-1}(x_{t-1})}{2^{2/2}} + \frac{F_t(x_t)}{2^{1/2}} \\
&amp;= ... ... \\
&amp;= \frac{x_1}{2^{t/2}} + \frac{F_1(x_1)}{2^{t/2}} + \frac{F_2(x_2)}{2^{(t-1)/2}} + ... ... + \frac{F_{t-1}(x_{t-1})}{2^{2/2}} + \frac{F_t(x_t)}{2^{1/2}}
\end{split}\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}\begin{split}
x_{t+1} &= \frac{x_t + F_t(x_t)}{\sqrt{2}} \\
&= \frac{x_t}{2^{1/2}} + \frac{F_t(x_t)}{2^{1/2}} \\
& = \frac{x_{t-1}}{2^{2/2}} + \frac{F_{t-1}(x_{t-1})}{2^{2/2}} + \frac{F_t(x_t)}{2^{1/2}} \\
&= \frac{x_{t-2}}{2^{3/2}} + \frac{F_{t-2}(x_{t-2})}{2^{3/2}} + \frac{F_{t-1}(x_{t-1})}{2^{2/2}} + \frac{F_t(x_t)}{2^{1/2}} \\
&= ... ... \\
&= \frac{x_1}{2^{t/2}} + \frac{F_1(x_1)}{2^{t/2}} + \frac{F_2(x_2)}{2^{(t-1)/2}} + ... ... + \frac{F_{t-1}(x_{t-1})}{2^{2/2}} + \frac{F_t(x_t)}{2^{1/2}}
\end{split}\end{equation}</script>
</div>
<p>上述推导出的公式的最后一行的含义为：模型的第 <span class="arithmatex"><span class="MathJax_Preview">t+1</span><script type="math/tex">t+1</script></span> 层的输出结果是由模型第1层的原始输入<span class="arithmatex"><span class="MathJax_Preview">x_1</span><script type="math/tex">x_1</script></span>、模型第1层的输出结果<span class="arithmatex"><span class="MathJax_Preview">F_1(x_1)</span><script type="math/tex">F_1(x_1)</script></span>、模型第2层的输出结果<span class="arithmatex"><span class="MathJax_Preview">F_2(x_2)</span><script type="math/tex">F_2(x_2)</script></span>直到模型第<span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>层的输出结果<span class="arithmatex"><span class="MathJax_Preview">F_t(x_t)</span><script type="math/tex">F_t(x_t)</script></span>加权求和得到的。</p>
<p>主要就是看这个加权中的权限值，第1层的原始输入、以及从第1层到第<span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>层的输出结果的权重为 <span class="arithmatex"><span class="MathJax_Preview">\Big\{\frac{1}{2^{t/2}}, \frac{1}{2^{t/2}}, \frac{1}{2^{(t-1)/2}}, ... ..., \frac{1}{2^{2/2}}, \frac{1}{2^{1/2}}\Big\}</span><script type="math/tex">\Big\{\frac{1}{2^{t/2}}, \frac{1}{2^{t/2}}, \frac{1}{2^{(t-1)/2}}, ... ..., \frac{1}{2^{2/2}}, \frac{1}{2^{1/2}}\Big\}</script></span>。可以明显的看出越靠前的层，其衰减的越严重。</p>
<p>综合来说：</p>
<ul>
<li>无论模型的哪一层，经过 Post Norm 之后其方差都被严格的控制到一个固定的范围；</li>
<li>Post Norm 会导致越靠前的层衰减的越严重，这和残差连接设计的初衷是相悖的。另外在实际使用中，使用了 Post Norm 之后模型训练起来也比较困难，必须要使用 warmup 等机制来保证模型收敛。</li>
</ul>
<h2 id="5pre-norm">5、Pre Norm<a class="headerlink" href="#5pre-norm" title="Permanent link">#</a></h2>
<p>Pre Norm 的公式为 <span class="arithmatex"><span class="MathJax_Preview">x_{t+1} = x_t + F_t(\text{Norm}(x_t))</span><script type="math/tex">x_{t+1} = x_t + F_t(\text{Norm}(x_t))</script></span></p>
<p>基于该公式，一直递归下去，得到的公式如下所示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}\begin{split}
x_{t+1} &amp;= x_t + F_t(\text{Norm}(x_t)) \\
&amp;= x_{t-1} + F_{t-1}(\text{Norm}(x_{t-1})) + F_t(\text{Norm}(x_t)) \\
&amp;= x_{t-2} + F_{t-2}(\text{Norm}(x_{t-2})) + F_{t-1}(\text{Norm}(x_{t-1})) + F_t(\text{Norm}(x_t)) \\
&amp;= ... ... \\
&amp;= x_1 + F_1(\text{Norm}(x_1)) + F_2(\text{Norm}(x_2)) + F_3(\text{Norm}(x_3)) + ... ... + F_{t-1}(\text{Norm}(x_{t-1})) + F_t(\text{Norm}(x_t))
\end{split}\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}\begin{split}
x_{t+1} &= x_t + F_t(\text{Norm}(x_t)) \\
&= x_{t-1} + F_{t-1}(\text{Norm}(x_{t-1})) + F_t(\text{Norm}(x_t)) \\
&= x_{t-2} + F_{t-2}(\text{Norm}(x_{t-2})) + F_{t-1}(\text{Norm}(x_{t-1})) + F_t(\text{Norm}(x_t)) \\
&= ... ... \\
&= x_1 + F_1(\text{Norm}(x_1)) + F_2(\text{Norm}(x_2)) + F_3(\text{Norm}(x_3)) + ... ... + F_{t-1}(\text{Norm}(x_{t-1})) + F_t(\text{Norm}(x_t))
\end{split}\end{equation}</script>
</div>
<p>由上述公式推导的最后一行可以看出，第 <span class="arithmatex"><span class="MathJax_Preview">t+1</span><script type="math/tex">t+1</script></span> 层模型的输出是由：第1层的原属输<span class="arithmatex"><span class="MathJax_Preview">x_1</span><script type="math/tex">x_1</script></span>、以及各层模型的输出直接求和得到的。相比于 Post Norm 对越靠前的层衰减越严重，这里的 Pre Norm 对待所有层的输出一视同仁，直接求和。</p>
<p>另外，容易看出随着层数的加深，整体的方差是在不断的增大的，所以使用 Pre Norm 时一般在最后一层之后再加个总的 Norm 层。</p>
<p>相比于 Post Norm，Pre Norm 能够真正的给靠前的层一个绿色通道，直达模型最终层。这样在反向传播时就不存在靠前的层梯度非常小的问题，所以 Pre Norm 训练起来要比 Post Norm 要容易训练。</p>
<p>每一层 <span class="arithmatex"><span class="MathJax_Preview">F_1</span><script type="math/tex">F_1</script></span>, <span class="arithmatex"><span class="MathJax_Preview">F_2</span><script type="math/tex">F_2</script></span>, ..., <span class="arithmatex"><span class="MathJax_Preview">F_{t-1}</span><script type="math/tex">F_{t-1}</script></span>, <span class="arithmatex"><span class="MathJax_Preview">F_t</span><script type="math/tex">F_t</script></span> 的输入都是经过 Norm 的，所以其输入都可看作方差为1的随机变量，而每一层的模型结构又是相同的，所以从统计上来看每一层的输出结果方差也是相同的。基于此，有一种观点认为当层数 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span> 比较大时，单层的输出对总输出的贡献是小量，此时有下述公式成立：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}\begin{split}
x_{t+2} &amp;= x_{t+1} + F_{t+1}(\text{Norm}(x_{t+1})) \\
&amp;= x_t + F_t(\text{Norm}(x_t)) + F_{t+1}(\text{Norm}(x_{t+1})) \\
&amp; \approx x_t + 2 \cdot F_t(\text{Norm}(x_t))
\end{split}\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}\begin{split}
x_{t+2} &= x_{t+1} + F_{t+1}(\text{Norm}(x_{t+1})) \\
&= x_t + F_t(\text{Norm}(x_t)) + F_{t+1}(\text{Norm}(x_{t+1})) \\
& \approx x_t + 2 \cdot F_t(\text{Norm}(x_t))
\end{split}\end{equation}</script>
</div>
<p>这样一个 <span class="arithmatex"><span class="MathJax_Preview">t+2</span><script type="math/tex">t+2</script></span> 层的网络就变成了一个更宽一些的 <span class="arithmatex"><span class="MathJax_Preview">t+1</span><script type="math/tex">t+1</script></span> 层的网络。由于现在整个深度学习都是使用反向传播，所以在相同的参数量下，宽而浅的网络训练起来是要比深而窄的网络要更好训练的，所以使用 Pre Norm 的网络比使用 Post Norm 的网络更好训练一些。</p>
<h2 id="6">6、两者对比<a class="headerlink" href="#6" title="Permanent link">#</a></h2>
<p>其实在上面的两个小节中，所以的内容都已经分析过了，这个小节只是做一下汇总。</p>
<table>
<thead>
<tr>
<th></th>
<th>Pre Norm</th>
<th>Post Norm</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>好训练</td>
<td>不好训练，基本必须要和warmup一起使用</td>
</tr>
<tr>
<td></td>
<td>对原始输入<span class="arithmatex"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>和各层网络的输出一视同仁，平权相加</td>
<td>非平权，越靠前的层衰减越严重</td>
</tr>
<tr>
<td></td>
<td>在对模型更新时，靠前层梯度大，靠后层的梯度小</td>
<td>在对模型更新时，靠前层梯度小，靠后层的梯度大</td>
</tr>
</tbody>
</table>
<h2 id="reference">Reference<a class="headerlink" href="#reference" title="Permanent link">#</a></h2>
<ul>
<li>
<p><a href="https://kexue.fm/archives/8620">https://kexue.fm/archives/8620</a></p>
</li>
<li>
<p><a href="https://kexue.fm/archives/9009">https://kexue.fm/archives/9009</a></p>
</li>
<li>
<p><a href="https://www.zhihu.com/question/519668254">https://www.zhihu.com/question/519668254</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/161505873">https://zhuanlan.zhihu.com/p/161505873</a></p>
</li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2021 Microsoft Research;<a href="https://beian.miit.gov.cn/">备案号：京ICP备2022025323号-1</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js" defer></script>
        <script src="../../../mathjax-config.js" defer></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
        <script src="../../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
