<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="mingchao.wang">
        <link rel="canonical" href="https://mingchao.wang/003_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/001_%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/06_%E5%9D%87%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%BC%82%E5%90%8C/">
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>Index - 算法工程师笔记</title>
        <link href="../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/obsidian.min.css">
        <link href="../../../css/extra.css" rel="stylesheet">

        <script src="../../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-274394082');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="../../..">算法工程师笔记</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/wmc1992/" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#_1" class="nav-link">均方差损失与交叉熵损失的异同</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#1" class="nav-link">1、均方差损失求导</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#11" class="nav-link">1.1 前向传播过程中符号的定义</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#12" class="nav-link">1.2 损失函数中的符号定义</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#13" class="nav-link">1.3 求导</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#2" class="nav-link">2、均方差损失与交叉熵损失的异同</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#3" class="nav-link">3、多分类任务时的异同</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#4" class="nav-link">4、总结</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p align="right">[<a href="/2X3X0mt7_no_toc/">隐藏左侧目录栏</a>][<a href="/2X3X0mt7/">显示左侧目录栏</a>]</p>

<h1 id="_1">均方差损失与交叉熵损失的异同<a class="headerlink" href="#_1" title="Permanent link">#</a></h1>
<p>关于交叉熵损失的求导在之前的文章 <a href="/aw6KH4ef/">二分类交叉熵损失求导</a> 中已经求解过了，本文会先对均方差损失求导，然后利用导数对比均方差损失和交叉熵损失。</p>
<h2 id="1">1、均方差损失求导<a class="headerlink" href="#1" title="Permanent link">#</a></h2>
<p>这里假设使用均方差损失做二分类任务；</p>
<h3 id="11">1.1 前向传播过程中符号的定义<a class="headerlink" href="#11" title="Permanent link">#</a></h3>
<p>模型假设为非常简单的：一个全连接层后面接sigmoid做二分类。那么其前向传播的公式为：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}z^{(i)}=\mathbf{W}\vec{x^{(i)}}\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}z^{(i)}=\mathbf{W}\vec{x^{(i)}}\end{equation}</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}\hat{y}^{(i)}=\sigma(z^{(i)})\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}\hat{y}^{(i)}=\sigma(z^{(i)})\end{equation}</script>
</div>
<p>在上述公式中：</p>
<ul>
<li>
<p>右上角的角标 <span class="arithmatex"><span class="MathJax_Preview">\cdot^{(i)}</span><script type="math/tex">\cdot^{(i)}</script></span> 表示第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本；</p>
</li>
<li>
<p><span class="arithmatex"><span class="MathJax_Preview">\vec{x^{(i)}}</span><script type="math/tex">\vec{x^{(i)}}</script></span> 表示第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本的输入特征，是一个向量；假设输入样本特征的维度为 <span class="arithmatex"><span class="MathJax_Preview">d_{input}</span><script type="math/tex">d_{input}</script></span>，则 <span class="arithmatex"><span class="MathJax_Preview">\vec{x^{(i)}} = [x^{(i)}_1, x^{(i)}_2, ..., x^{(i)}_{d_{input}}]</span><script type="math/tex">\vec{x^{(i)}} = [x^{(i)}_1, x^{(i)}_2, ..., x^{(i)}_{d_{input}}]</script></span>；</p>
</li>
<li>
<p><span class="arithmatex"><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span> 是权重矩阵；</p>
</li>
<li>
<p><span class="arithmatex"><span class="MathJax_Preview">\sigma(\cdot)</span><script type="math/tex">\sigma(\cdot)</script></span> 表示sigmoid函数；</p>
</li>
<li>
<p><span class="arithmatex"><span class="MathJax_Preview">z^{(i)}</span><script type="math/tex">z^{(i)}</script></span> 表示全连接层的输出，同时也是sigmoid层的输入，其是一个标量；</p>
</li>
<li>
<p><span class="arithmatex"><span class="MathJax_Preview">\hat{y}^{(i)}</span><script type="math/tex">\hat{y}^{(i)}</script></span> 是sigmoid层的输出，也是一个标量，表示的是模型对第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本预测为正例的概率，使用该值和 <span class="arithmatex"><span class="MathJax_Preview">y^{(i)}</span><script type="math/tex">y^{(i)}</script></span> 比较计算损失；</p>
</li>
</ul>
<h3 id="12">1.2 损失函数中的符号定义<a class="headerlink" href="#12" title="Permanent link">#</a></h3>
<p>损失函数的公式，如下所示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L^{(i)}=\frac{1}{2}(y^{(i)} - \hat{y}^{(i)})^2\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L^{(i)}=\frac{1}{2}(y^{(i)} - \hat{y}^{(i)})^2\end{equation}</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L=\frac{1}{N} \sum_{i=1}^N L^{(i)}\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L=\frac{1}{N} \sum_{i=1}^N L^{(i)}\end{equation}</script>
</div>
<p>上述公式中的公式（4）只是对每条样本的损失 <span class="arithmatex"><span class="MathJax_Preview">L^{(i)}</span><script type="math/tex">L^{(i)}</script></span> 求均值，<span class="arithmatex"><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> 表示样本的总数，比较简单。后面的分析和求导将只对公式（3）进行。</p>
<h3 id="13">1.3 求导<a class="headerlink" href="#13" title="Permanent link">#</a></h3>
<h4 id="131-fracpartial-lipartial-wfracpartial-lipartial-w-fracpartial-lipartial-zifracpartial-lipartial-zi">1.3.1 说明 <span class="arithmatex"><span class="MathJax_Preview">\frac{\partial L^{(i)}}{\partial w}</span><script type="math/tex">\frac{\partial L^{(i)}}{\partial w}</script></span> 与 <span class="arithmatex"><span class="MathJax_Preview">\frac{\partial L^{(i)}}{\partial z^{(i)}}</span><script type="math/tex">\frac{\partial L^{(i)}}{\partial z^{(i)}}</script></span> 的区别<a class="headerlink" href="#131-fracpartial-lipartial-wfracpartial-lipartial-w-fracpartial-lipartial-zifracpartial-lipartial-zi" title="Permanent link">#</a></h4>
<p>根据链式求导法则，<span class="arithmatex"><span class="MathJax_Preview">\frac{\partial L^{(i)}}{\partial w}</span><script type="math/tex">\frac{\partial L^{(i)}}{\partial w}</script></span> 可以分为三部分，如下式所示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}
\frac{\partial L^{(i)}}{\partial w} = \frac{\partial L^{(i)}}{\partial \hat{y}^{(i)}} \frac{\partial \hat{y}^{(i)}}{\partial z^{(i)}} \frac{\partial z^{(i)}}{\partial w}
\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}
\frac{\partial L^{(i)}}{\partial w} = \frac{\partial L^{(i)}}{\partial \hat{y}^{(i)}} \frac{\partial \hat{y}^{(i)}}{\partial z^{(i)}} \frac{\partial z^{(i)}}{\partial w}
\end{equation}</script>
</div>
<p><span class="arithmatex"><span class="MathJax_Preview">\frac{\partial L^{(i)}}{\partial z^{(i)}}</span><script type="math/tex">\frac{\partial L^{(i)}}{\partial z^{(i)}}</script></span> 可以分为两部分，如下式所示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}
\frac{\partial L^{(i)}}{\partial z^{(i)}} = \frac{\partial L^{(i)}}{\partial \hat{y}^{(i)}} \frac{\partial \hat{y}^{(i)}}{\partial z^{(i)}}
\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}
\frac{\partial L^{(i)}}{\partial z^{(i)}} = \frac{\partial L^{(i)}}{\partial \hat{y}^{(i)}} \frac{\partial \hat{y}^{(i)}}{\partial z^{(i)}}
\end{equation}</script>
</div>
<p>它们之间相差了一个 <span class="arithmatex"><span class="MathJax_Preview">\frac{\partial z^{(i)}}{\partial w}</span><script type="math/tex">\frac{\partial z^{(i)}}{\partial w}</script></span>，由前向传播的公式可知，这个导数取决于sigmoid层之前的网络结构是什么样的。在本文的 1.1 部分假设是一个全连接层，所以其导数为 <span class="arithmatex"><span class="MathJax_Preview">\frac{\partial z^{(i)}}{\partial w}=\vec{x^{(i)}}</span><script type="math/tex">\frac{\partial z^{(i)}}{\partial w}=\vec{x^{(i)}}</script></span>；但其也可以是CNN层、RNN层、Transformer层等等，所以对于不同的网络 <span class="arithmatex"><span class="MathJax_Preview">\frac{\partial z^{(i)}}{\partial w}</span><script type="math/tex">\frac{\partial z^{(i)}}{\partial w}</script></span> 有着不同的求解方式，其并不属于二分类交叉熵损失部分的求导。所以本文后面在求导时求解的是 <span class="arithmatex"><span class="MathJax_Preview">\frac{\partial L^{(i)}}{\partial z^{(i)}}</span><script type="math/tex">\frac{\partial L^{(i)}}{\partial z^{(i)}}</script></span>。</p>
<h4 id="132-fracpartial-lipartial-zifracpartial-lipartial-zi">1.3.2 求 <span class="arithmatex"><span class="MathJax_Preview">\frac{\partial L^{(i)}}{\partial z^{(i)}}</span><script type="math/tex">\frac{\partial L^{(i)}}{\partial z^{(i)}}</script></span><a class="headerlink" href="#132-fracpartial-lipartial-zifracpartial-lipartial-zi" title="Permanent link">#</a></h4>
<p>求导过程非常简单，如下所示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}\begin{split}
\frac{\partial L^{(i)}}{\partial z^{(i)}} &amp;= \frac{\partial L^{(i)}}{\partial \hat{y}^{(i)}} \frac{\partial \hat{y}^{(i)}}{\partial z^{(i)}} \\
&amp;= (\hat{y}^{(i)} - y^{(i)}) \sigma^{\prime}(z^{(i)})
\end{split}\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}\begin{split}
\frac{\partial L^{(i)}}{\partial z^{(i)}} &= \frac{\partial L^{(i)}}{\partial \hat{y}^{(i)}} \frac{\partial \hat{y}^{(i)}}{\partial z^{(i)}} \\
&= (\hat{y}^{(i)} - y^{(i)}) \sigma^{\prime}(z^{(i)})
\end{split}\end{equation}</script>
</div>
<p>其中 <span class="arithmatex"><span class="MathJax_Preview">\sigma^{\prime}( \cdot )</span><script type="math/tex">\sigma^{\prime}( \cdot )</script></span> 表示sigmoid函数的导数；</p>
<h2 id="2">2、均方差损失与交叉熵损失的异同<a class="headerlink" href="#2" title="Permanent link">#</a></h2>
<p>在文章 <a href="/aw6KH4ef/">二分类交叉熵损失求导</a> 中已经求解出了二分类交叉熵损失的导数，下面将均方差损失的导数和交叉熵损失的导数都放到这里进行对比：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}\begin{split}
&amp;\frac{\partial L^{(i)}}{\partial z^{(i)}}=\hat{y}^{(i)} - y^{(i)} \qquad // \text{二分类交叉熵损失的梯度} \\
&amp;\frac{\partial L_i}{\partial z^{(i)}}=(\hat{y}^{(i)} - y^{(i)}) \sigma^{\prime}(z^{(i)}) \qquad// \text{二分类均方差损失的梯度}
\end{split}\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}\begin{split}
&\frac{\partial L^{(i)}}{\partial z^{(i)}}=\hat{y}^{(i)} - y^{(i)} \qquad // \text{二分类交叉熵损失的梯度} \\
&\frac{\partial L_i}{\partial z^{(i)}}=(\hat{y}^{(i)} - y^{(i)}) \sigma^{\prime}(z^{(i)}) \qquad// \text{二分类均方差损失的梯度}
\end{split}\end{equation}</script>
</div>
<p>先分析Sigmoid函数的性质。下图为Sigmoid函数的图像，可以看出当 <span class="arithmatex"><span class="MathJax_Preview">z_i</span><script type="math/tex">z_i</script></span> 比较小或者比较大时， <span class="arithmatex"><span class="MathJax_Preview">\sigma^{\prime}(z_i)</span><script type="math/tex">\sigma^{\prime}(z_i)</script></span> 的值（即下图曲线的斜率）都趋于0；也就是说当 <span class="arithmatex"><span class="MathJax_Preview">z_i</span><script type="math/tex">z_i</script></span> 比较小或者比较大时，其梯度也是趋于0的。</p>
<p><img alt="" src="/003_深度学习/001_损失函数/06_均方差损失与交叉熵损失异同/assets/01.png" /></p>
<p>在做梯度下降时，希望当离目标较远时，每次更新的步长要大一些，可以快速收敛；当离目标较近时，每次更新的步长要小一些，可以防止在目标值附近震荡；</p>
<p>对比交叉熵损失和均方差损失的梯度，可以看出它们两个只差一个 <span class="arithmatex"><span class="MathJax_Preview">\sigma^{\prime}(z^{(i)})</span><script type="math/tex">\sigma^{\prime}(z^{(i)})</script></span> ，所以有如下结论：</p>
<ul>
<li>
<p>使用交叉熵损失做二分类任务时，其梯度为期望输出与实际输出的差值，当距离目标点越远时，该差值越大，梯度越大；当距离目标点越近时，该差值越小，梯度越小；这符合之前所希望的；</p>
</li>
<li>
<p>使用均方差损失做而分类任务时，由于其梯度中包含了 <span class="arithmatex"><span class="MathJax_Preview">\sigma^{\prime}(z^{(i)})</span><script type="math/tex">\sigma^{\prime}(z^{(i)})</script></span> 这一项，当距离目标点比较远时，梯度较小（趋于0）；当距离目标点较近时，梯度也较小（趋于0），不利于优化；</p>
</li>
</ul>
<h2 id="3">3、多分类任务时的异同<a class="headerlink" href="#3" title="Permanent link">#</a></h2>
<p>上面两部分的分析是使用交叉熵损失和均方差损失做二分类任务时的区别，在多分类任务上分析过程是类似的，步骤为：</p>
<ul>
<li>求解交叉熵损失在多分类时的梯度；</li>
<li>求解均方差损失在多分类时的梯度；</li>
<li>对比分析两个梯度在做梯度下降时的效果；</li>
</ul>
<p>多分类交叉熵的梯度前面已经求解过了，详情见: <a href="/llmTwIe5/">多分类交叉熵损失求导</a></p>
<p>均方差损失在做多分类任务时，梯度的求解非常复杂，奈何数学不好，先空着，以后再看；</p>
<h2 id="4">4、总结<a class="headerlink" href="#4" title="Permanent link">#</a></h2>
<p>本文主要是对比了交叉熵损失和均方差损失在做 <strong>分类任务</strong> 时的异同。在二分类任务中，均方差损失的梯度中由于存在 <span class="arithmatex"><span class="MathJax_Preview">\sigma^{\prime}(z^{(i)})</span><script type="math/tex">\sigma^{\prime}(z^{(i)})</script></span> 这一项，导致其在距离目标点非常远和非常近时的梯度都较小，使得优化效果较差。另外多分类任务的均方差损失的梯度由于分析比较复杂，没有做详细分析。</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2021 Microsoft Research;<a href="https://beian.miit.gov.cn/">备案号：京ICP备2022025323号-1</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js" defer></script>
        <script src="../../../mathjax-config.js" defer></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
        <script src="../../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
