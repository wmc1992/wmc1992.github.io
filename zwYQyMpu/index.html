<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="mingchao.wang">
        <link rel="canonical" href="https://mingchao.wang/006_LLM/002_%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/007_LLaMA2%E6%A8%A1%E5%9E%8B/LLaMA2ChatModel%E6%8E%A8%E7%90%86%E4%BB%A3%E7%A0%81%E8%AF%B4%E6%98%8E/">
        <link rel="shortcut icon" href="../../../../img/favicon.ico">
        <title>Index - ç®—æ³•å·¥ç¨‹å¸ˆç¬”è®°</title>
        <link href="../../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/obsidian.min.css">
        <link href="../../../../css/extra.css" rel="stylesheet">

        <script src="../../../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-274394082');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="../../../..">ç®—æ³•å·¥ç¨‹å¸ˆç¬”è®°</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/wmc1992/" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#llama2-chat-model" class="nav-link">LLaMA2-Chat-Model æ¨ç†ä»£ç </a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#1" class="nav-link">1ã€å¯¹è¯æ•°æ®æ„é€ è§„åˆ™è¯´æ˜</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#2" class="nav-link">2ã€æ¨ç†ä»£ç </a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#3" class="nav-link">3ã€å®Œæ•´æ¨ç†ä»£ç </a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#reference" class="nav-link">Reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p align="right">[<a href="/zwYQyMpu_no_toc/">éšè—å·¦ä¾§ç›®å½•æ </a>][<a href="/zwYQyMpu/">æ˜¾ç¤ºå·¦ä¾§ç›®å½•æ </a>]</p>

<h1 id="llama2-chat-model">LLaMA2-Chat-Model æ¨ç†ä»£ç <a class="headerlink" href="#llama2-chat-model" title="Permanent link">#</a></h1>
<h2 id="1">1ã€å¯¹è¯æ•°æ®æ„é€ è§„åˆ™è¯´æ˜<a class="headerlink" href="#1" title="Permanent link">#</a></h2>
<p>å®˜æ–¹ç»™å‡ºçš„æ¨ç†ä»£ç çš„è„šæœ¬ä¸º <a href="https://github.com/facebookresearch/llama/blob/main/llama/generation.py">generation.py</a>ï¼Œè¯¥è„šæœ¬ä¸­å¯¹äºå¯¹è¯æ•°æ®çš„æ„é€ è¿‡ç¨‹è¯´æ˜å¦‚ä¸‹ã€‚</p>
<p>LLaMA2 ä¼šå°†å¯¹è¯æ•°æ®æ„é€ ä¸ºå¦‚ä¸‹å½¢å¼ï¼š</p>
<pre><code>&lt;bos&gt; B_INST B_SYS SytemPrompt E_SYS UserPrompt E_INST Answer &lt;eos&gt;
</code></pre>
<p>å½“å¯¹è¯æœ‰å¤šè½®æ—¶ç»§ç»­åœ¨åé¢æ·»åŠ ï¼Œä¹Ÿå°±æ˜¯å¦‚ä¸‹å½¢å¼ï¼š</p>
<pre><code>&lt;bos&gt; B_INST B_SYS SytemPrompt E_SYS UserPrompt1 E_INST Answer1 &lt;eos&gt; &lt;bos&gt; B_INST UserPrompt2 E_INST Answer2 &lt;eos&gt; &lt;bos&gt; B_INST UserPrompt3 E_INST Answer3 &lt;eos&gt;
</code></pre>
<p>ä¸Šé¢çš„ B_INSTã€E_INSTã€B_SYSã€E_SYS éƒ½æ˜¯ä¸€äº›ç‰¹æ®Šçš„å­—ç¬¦ï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="language-python">B_INST = &quot;[INST]&quot;
E_INST = &quot;[/INST]&quot;
B_SYS = &quot;&lt;&lt;SYS&gt;&gt;\n&quot;
E_SYS = &quot;\n&lt;&lt;/SYS&gt;&gt;\n\n&quot;
</code></pre>
<p>å¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®š system promptï¼Œä¼šç»™è‡ªåŠ¨åŠ ä¸Šæ¨¡å‹çš„ system promptï¼›å¦‚æœç”¨æˆ·è‡ªå·±æŒ‡å®šäº†ï¼Œåˆ™ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ promptã€‚é»˜è®¤çš„ system prompt ä¸ºï¼š</p>
<pre><code class="language-python">DEFAULT_SYSTEM_PROMPT = &quot;&quot;&quot;You are a helpful, respectful and honest assistant. Always answer as helpfully as \
possible, while being safe. Your answers should not include any harmful, unethical, \
racist, sexist, toxic, dangerous, or illegal content. Please ensure that your \
responses are socially unbiased and positive in nature.

If a question does not make any sense, or is not factually coherent, explain why \
instead of answering something not correct. If you don't know the answer to a question, \
please don't share false information.&quot;&quot;&quot;
</code></pre>
<p>ä¸Šé¢æ˜¯ä¸€äº›è§„åˆ™ï¼Œä¸‹é¢ä¸¾ä¸¤ä¸ªğŸŒ°è¯´æ˜ä¸€ä¸‹ã€‚ç¬¬ä¸€ç»„æ˜¯ä¸€ä¸ªå•è½®å¯¹è¯çš„ğŸŒ°ï¼Œå¹¶ä¸”ç”¨æˆ·è‡ªå·±æŒ‡å®šäº† system promptï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="language-json">[
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Always answer with emojis&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How to go from Beijing to NY?&quot;},
]
</code></pre>
<p>å…¶æ„é€ å‡ºæ¥çš„æ¨¡å‹è¾“å…¥ä¸ºå¦‚ä¸‹å½¢å¼ï¼š</p>
<pre><code>&lt;s&gt; [INST] &lt;&lt;SYS&gt;&gt;
Always answer with emojis
&lt;&lt;/SYS&gt;&gt;

How to go from Beijing to NY? [/INST]
</code></pre>
<p>ç¬¬äºŒç»„æ˜¯ä¸€ä¸ªå¤šè½®å¯¹è¯çš„ğŸŒ°ï¼Œå¹¶ä¸”ç”¨æˆ·æ²¡æœ‰è‡ªå·±æŒ‡å®š system promptï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="language-json">[
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who are you?&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Hello! I'm just an AI, my purpose is to assist and ... and I will do my best to assist you.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;é‚£ä½ ä¼šè¯´ä¸­æ–‡å—ï¼Ÿ&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Yes, I can speak Chinese. I'm just an AI, I don't have a physical voice, but I can communicate in Chinese text. Would you like to chat in Chinese?&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;æ˜¯çš„ï¼Œæ¥ä¸‹æ¥è¯·ç”¨ä¸­æ–‡èŠå¤©ã€‚&quot;},
]
</code></pre>
<p>å…¶æ„é€ å‡ºæ¥çš„æ¨¡å‹è¾“å…¥ä¸ºå¦‚ä¸‹å½¢å¼ï¼š</p>
<pre><code>&lt;s&gt; [INST] &lt;&lt;SYS&gt;&gt;
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.

If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
&lt;&lt;/SYS&gt;&gt;

Who are you? [/INST] Hello! I'm just an AI, my purpose is to assist and ... and I will do my best to assist you. &lt;/s&gt;&lt;s&gt; [INST] é‚£ä½ ä¼šè¯´ä¸­æ–‡å—ï¼Ÿ [/INST] Yes, I can speak Chinese. I'm just an AI, I don't have a physical voice, but I can communicate in Chinese text. Would you like to chat in Chinese? &lt;/s&gt;&lt;s&gt; [INST] æ˜¯çš„ï¼Œæ¥ä¸‹æ¥è¯·ç”¨ä¸­æ–‡èŠå¤©ã€‚ [/INST]
</code></pre>
<blockquote>
<p>PS: å¯¹äºè¿™ä¸ªä¾‹å­ï¼Œè™½ç„¶æ¨¡å‹è¯´å®ƒå¯ä»¥ä½¿ç”¨ä¸­æ–‡ï¼Œä½†æ˜¯å®é™…ä¸Šè¿˜æ˜¯åªè¾“å‡ºè‹±æ–‡ã€‚æ•´ç†æµ‹è¯•çš„æ•ˆæœæ˜¯ï¼šå¯ä»¥ç†è§£ä¸­æ–‡ï¼Œä½†æ˜¯ä¸ä¼šè¾“å‡ºä¸­æ–‡ã€‚</p>
</blockquote>
<h2 id="2">2ã€æ¨ç†ä»£ç <a class="headerlink" href="#2" title="Permanent link">#</a></h2>
<p>ä¸‹é¢åŸºäº huggingface çš„å„ç§æ¡†æ¶è¯´æ˜ä¸€ä¸‹ LLaMA2-Chat-Model çš„æ¨ç†ä»£ç ã€‚</p>
<p>åœ¨ç±» <code>LlamaTokenizer</code> ä¸­æ–°å¢äº†ä¸€ä¸ªå‡½æ•° <a href="https://github.com/huggingface/transformers/blob/v4.31.0/src/transformers/models/llama/tokenization_llama.py#L334">_build_conversation_input_ids()</a>ï¼Œè¯¥å‡½æ•°å°±æ˜¯ç”¨äºå®ç°ä¸Šè¿°å¯¹è¯æ•°æ®æ„é€ è§„åˆ™çš„ã€‚è¯¥å‡½æ•°çš„è¾“å…¥æ˜¯ä¸€ä¸ª <a href="https://github.com/huggingface/transformers/blob/v4.31.0/src/transformers/pipelines/conversational.py#L18">Conversation</a> ç±»å‹çš„å¯¹è±¡ï¼Œè¿™ä¸ªç±»éå¸¸ç®€å•ï¼Œå…ˆè¯´æ˜ä¸€ä¸‹è¿™ä¸ªç±»ã€‚</p>
<pre><code>Conversation(text, past_user_inputs=[], generated_responses=[])
</code></pre>
<p>å¦‚ä¸Šè¿°ä»£ç æ‰€ç¤ºï¼Œåˆ›å»ºè¯¥ç±»æ—¶ä¼ å…¥ä¸‰ä¸ªå‚æ•°ï¼š</p>
<ul>
<li><code>past_user_inputs</code>: æ˜¯ä¸€ä¸ªlistç±»å‹ï¼Œæ˜¯å†å²èŠå¤©è¿‡ç¨‹ä¸­ï¼Œuser çš„æ‰€æœ‰æé—®ï¼›</li>
<li><code>generated_responses</code>: æ˜¯ä¸€ä¸ªlistç±»å‹ï¼Œæ˜¯å†å²èŠå¤©è¿‡ç¨‹ä¸­ï¼Œassistant çš„æ‰€æœ‰å›ç­”ï¼›</li>
<li><code>text</code>: strç±»å‹ï¼Œæ˜¯æœ€æ–°ä¸€æ¬¡çš„ user çš„æé—®ï¼›</li>
</ul>
<p>è¦æ³¨æ„ï¼Œå­—æ®µ <code>past_user_inputs</code> ä¸å­—æ®µ <code>generated_responses</code> å¿…é¡»æ˜¯ä¸€ä¸€å¯¹åº”çš„ï¼Œæ„é€ æ—¶æ˜¯ <code>zip(past_user_inputs, generated_responses)</code> è¿™ä¹ˆå¯¹åº”çš„ã€‚</p>
<p>çœ‹å®Œ Conversation è¿™ä¸ªç±»çš„ä¸‰ä¸ªå­—æ®µå°±ä¼šå‘ç°è¿™ä¸ªç±»é‡Œé¢æ²¡æœ‰ç»™ system prompt é¢„ç•™ä¸€ä¸ªå­—æ®µï¼Œæ‰€ä»¥åœ¨å‡½æ•° <a href="https://github.com/huggingface/transformers/blob/v4.31.0/src/transformers/models/llama/tokenization_llama.py#L334">_build_conversation_input_ids()</a> ç”¨äº†ä¸€ä¸ªæŠ˜è¡·çš„æ–¹æ³•ï¼Œå®ƒæ˜¯æ£€æµ‹åˆ—è¡¨ <code>past_user_inputs</code> ä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å¦åŒ…å« <code>B_SYS</code> æˆ–è€… <code>E_SYS</code> æ¥åˆ¤æ–­ç”¨æˆ·æ˜¯å¦è‡ªå·±æŒ‡å®šäº† system promptã€‚æ‰€ä»¥å¦‚æœæƒ³è¦è‡ªå·±æŒ‡å®š system promptï¼Œåœ¨åˆ›å»ºå¯¹è±¡ Conversation ä¹‹å‰éœ€è¦è‡ªå·±å¤„ç†ä¸€ä¸‹ï¼Œä»£ç å¦‚ä¸‹ï¼š</p>
<pre><code class="language-python">B_SYS, E_SYS = &quot;&lt;&lt;SYS&gt;&gt;\n&quot;, &quot;\n&lt;&lt;/SYS&gt;&gt;\n\n&quot;

# dialog ä¸¾ä¾‹: [
#     {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Always answer with emojis&quot;},
#     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How to go from Beijing to NY?&quot;},
# ]
if dialog[0][&quot;role&quot;] == &quot;system&quot;:  # æŠŠè‡ªå·±æŒ‡å®šçš„ system prompt åˆå¹¶åˆ° user çš„ç¬¬ä¸€æ¬¡çš„é—®é¢˜ä¸­
    dialog = [
        {
            &quot;role&quot;: dialog[1][&quot;role&quot;],
            &quot;content&quot;: B_SYS + dialog[0][&quot;content&quot;] + E_SYS + dialog[1][&quot;content&quot;],
        }
    ] + dialog[2:]

conversation = Conversation(
    text=dialog[-1][&quot;content&quot;],
    past_user_inputs=[item[&quot;content&quot;] for item in dialog[:-1] if item[&quot;role&quot;] == &quot;user&quot;],
    generated_responses=[item[&quot;content&quot;] for item in dialog[:-1] if item[&quot;role&quot;] == &quot;assistant&quot;]
)
</code></pre>
<p>ç›¸å¯¹å®Œæ•´çš„æ¨ç†ä»£ç ç‰‡æ®µå¦‚ä¸‹ï¼š</p>
<pre><code class="language-python">import torch
from transformers.pipelines.conversational import Conversation

model = ...
tokenizer = ...

dialog = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Always answer with Haiku&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;I am going to Paris, what should I see?&quot;},
]

# æ„é€ æˆconversationæ ¼å¼æ•°æ®

B_SYS, E_SYS = &quot;&lt;&lt;SYS&gt;&gt;\n&quot;, &quot;\n&lt;&lt;/SYS&gt;&gt;\n\n&quot;
if dialog[0][&quot;role&quot;] == &quot;system&quot;:  # æŠŠè‡ªå·±æŒ‡å®šçš„ system prompt åˆå¹¶åˆ° user çš„ç¬¬ä¸€æ¬¡çš„é—®é¢˜ä¸­
    dialog = [
        {
            &quot;role&quot;: dialog[1][&quot;role&quot;],
            &quot;content&quot;: B_SYS + dialog[0][&quot;content&quot;] + E_SYS + dialog[1][&quot;content&quot;],
        }
    ] + dialog[2:]

# æ£€æŸ¥ dialog æ˜¯å¦æ˜¯ (u/a/u/a/u...) çš„æ ¼å¼
assert all([msg[&quot;role&quot;] == &quot;user&quot; for msg in dialog[::2]]) and all(
    [msg[&quot;role&quot;] == &quot;assistant&quot; for msg in dialog[1::2]]
), (
    &quot;model only supports 'system', 'user' and 'assistant' roles, &quot;
    &quot;starting with 'system', then 'user' and alternating (u/a/u/a/u...)&quot;
)
assert (dialog[-1][&quot;role&quot;] == &quot;user&quot;), f&quot;Last message must be from user, got {dialog[-1]['role']}&quot;

conversation = Conversation(
    text=dialog[-1][&quot;content&quot;],
    past_user_inputs=[item[&quot;content&quot;] for item in dialog[:-1] if item[&quot;role&quot;] == &quot;user&quot;],
    generated_responses=[item[&quot;content&quot;] for item in dialog[:-1] if item[&quot;role&quot;] == &quot;assistant&quot;]
)

# æ¨ç†
with torch.no_grad():
    input_ids = tokenizer._build_conversation_input_ids(conversation)
    input_ids = torch.tensor([input_ids])

    out = model.generate(
        input_ids=input_ids.cuda(),
        max_new_tokens=512,
        top_p=0.9,
        temperature=0.6,
    )

    out_text = tokenizer.decode(out[0])
    print(out_text)
    print(&quot;=&quot; * 100)
</code></pre>
<h2 id="3">3ã€å®Œæ•´æ¨ç†ä»£ç <a class="headerlink" href="#3" title="Permanent link">#</a></h2>
<p>è¯¦è§: <a href="https://github.com/wmc1992/transformers_add_lora/blob/master/core/llama2/inference_with_qlora.py">https://github.com/wmc1992/transformers_add_lora/blob/master/core/llama2/inference_with_qlora.py</a></p>
<h2 id="reference">Reference<a class="headerlink" href="#reference" title="Permanent link">#</a></h2>
<ul>
<li>
<p><a href="https://github.com/facebookresearch/llama">https://github.com/facebookresearch/llama</a></p>
</li>
<li>
<p><a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
</li>
<li>
<p><a href="https://github.com/artidoro/qlora">https://github.com/artidoro/qlora</a></p>
</li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2021 Microsoft Research;<a href="https://beian.miit.gov.cn/">å¤‡æ¡ˆå·ï¼šäº¬ICPå¤‡2022025323å·-1</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../../js/base.js" defer></script>
        <script src="../../../../mathjax-config.js" defer></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
        <script src="../../../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
