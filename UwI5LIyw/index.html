<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="mingchao.wang">
        <link rel="canonical" href="https://mingchao.wang/006_LLM/001_PromptEngineering-MindsEye/">
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Mind's Eye - 算法工程师笔记</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/obsidian.min.css">
        <link href="../../css/extra.css" rel="stylesheet">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-274394082');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="../..">算法工程师笔记</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/wmc1992/" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#minds-eye" class="nav-link">Mind's Eye</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#background" class="nav-link">Background</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_1" class="nav-link">本文的贡献</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#utopia" class="nav-link">数据集UTOPIA简述</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#minds-eye_1" class="nav-link">Mind's Eye具体做法</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_2" class="nav-link">实验结果</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#_3" class="nav-link">效果分析</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#_4" class="nav-link">消融实验</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_6" class="nav-link">相关工作</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="minds-eye">Mind's Eye<a class="headerlink" href="#minds-eye" title="Permanent link">#</a></h1>
<h2 id="background">Background<a class="headerlink" href="#background" title="Permanent link">#</a></h2>
<p>为了解决模型推理能力不足的问题，之前的工作大致有：</p>
<ul>
<li>通过人工设计提示的方式，引导模型更好的推理。该方法的缺点是其只能依赖模型中永久存在的知识，而模型中学到的知识可能是不正确或过时的；</li>
<li>检索增强型LMs（retrieval-augmented LMs），结合检索的内容和问题让模型进行推理，甚至还可以用 (问题,文档,答案) 这种三元组在模型上微调；</li>
</ul>
<h2 id="_1">本文的贡献<a class="headerlink" href="#_1" title="Permanent link">#</a></h2>
<p>本文的贡献总共有三部分，如下：</p>
<ul>
<li>
<p>提出了一个新的数据集：UTOPIA，该数据集主要是用于测试模型对物理定律的推理能力。该数据集包含39个子任务，涵盖6种常见的物理场景。</p>
</li>
<li>
<p>提出一种将物理引擎的模拟结果添加到模型中的新范式：(1)使用code-to-text模型将文本形式的问题转换为物理模拟引擎可执行的代码；(2)在物理模拟引擎中使用上述代码进行模拟；(3)将模拟结果和文本问题都加入到LM的提示中进行推理。将这种方法称为 Mind's Eye。</p>
</li>
<li>
<p>系统的评估 Mind's Eye 这种方法的效果。</p>
</li>
</ul>
<h2 id="utopia">数据集UTOPIA简述<a class="headerlink" href="#utopia" title="Permanent link">#</a></h2>
<p>该数据集中总共有6个常见的物理场景："Motion"、"Friction"、"Free fall"、"Projection"、"Collision"、"Incline"。这些场景主要来自于中学教科书。然后该数据集中的问题和答案的描述上也尽量贴近教科书中的描述方式。</p>
<p>该数据集中的所有问题的答案都是使用模拟器生成的。数据集简介如下图：</p>
<p><img alt="" src="/006_LLM/001_PromptEngineering-MindsEye/assets/Table1.png" /></p>
<h2 id="minds-eye_1">Mind's Eye具体做法<a class="headerlink" href="#minds-eye_1" title="Permanent link">#</a></h2>
<ol>
<li>
<p>使用code-to-text模型将文本形式的问题转换为物理模拟引擎可执行的代码；</p>
</li>
<li>
<p>在物理模拟引擎中使用上述代码进行模拟；</p>
</li>
<li>
<p>将模拟结果和文本问题都加入到LM的提示中进行推理。</p>
</li>
</ol>
<p>下图是 Vanilla、Chain-of-Thought、Mind's Eye 三种方式的流程图：</p>
<p><img alt="" src="/006_LLM/001_PromptEngineering-MindsEye/assets/Figure1.png" /></p>
<h2 id="_2">实验结果<a class="headerlink" href="#_2" title="Permanent link">#</a></h2>
<h3 id="_3">效果分析<a class="headerlink" href="#_3" title="Permanent link">#</a></h3>
<p>第一部分的效果分析是对比"不同尺寸的模型"、"使用Mind's Eye与否"的效果差别。</p>
<p><img alt="" src="/006_LLM/001_PromptEngineering-MindsEye/assets/Figure2.png" /></p>
<ul>
<li>
<p>上图中，蓝色是zero-shot下的不同模型的效果。橙色是few-shot下的不同模型的效果。可以看出虽然较大的模型效果始终比较小的模型效果较好，但是推理能力似乎在达到一定的程度之后趋于稳定。尤其是上图中橙色的线，随着模型的增大效果的提升想对比较小。</p>
</li>
<li>
<p>上图中，紫色线是使用Mind's Eye做zero-shot，红色线是使用Mind's Eye做few-shot。可以看出加上Mind's Eye之后无论是zero-shot还是few-shot都随着模型的增大，推理能力大幅提升。（这是为什么？）</p>
</li>
<li>
<p>另外，使用了Mind's Eye之后，小尺寸的模型甚至能够匹配大尺寸的模型。比如上图中350M GPT-3的Mind's Eye zero-shot的结果为29.0%，175B GPT-3的zero-shot的结果也为29.0%。</p>
</li>
</ul>
<p>第二部分是对比Mind's Eye与其他的推理增强方法的效果。</p>
<p><img alt="" src="/006_LLM/001_PromptEngineering-MindsEye/assets/Table3.png" /></p>
<p>参与对比的方法有：Zero-shot CoT、CoT、self-Consistency、DiVerSe、RAG、T0、Minerva、Instruct-GPT；</p>
<p>然后上图中各种其他方法使用的模型的尺寸在论文中没有明说，猜测应该是175B的模型。</p>
<p>对比结论如下：</p>
<ul>
<li>
<p>相比于较小的模型，Mind's Eye对较大的模型的提升更大一些，这个结论在图2中也可以可以得出。</p>
</li>
<li>
<p>Mind's Eye加上Instruct-GPT之后，几乎可以得到满分。猜测：当模型对推理结果有很好的依据（Mind's Eye）并且模型能够很好的理解指令（Instruct-GPT）时，模型就能够做非常完美的对齐。</p>
</li>
<li>
<p>之前的像"Better Prompting"和"Optimized Decoding"对效果的提升是有限的，猜测：原因就是这些方法依赖于模型中已经存储的知识。</p>
</li>
</ul>
<h3 id="_4">消融实验<a class="headerlink" href="#_4" title="Permanent link">#</a></h3>
<h4 id="_5">物理引擎的模拟结果真的被需要吗？<a class="headerlink" href="#_5" title="Permanent link">#</a></h4>
<p><img alt="" src="/006_LLM/001_PromptEngineering-MindsEye/assets/Table4.png" /></p>
<p>设计了以下三个消融实验：</p>
<ul>
<li>
<p>答非所问（Mismatched simulation results）：比如题目中询问速度相关的物理知识，我们给它添上加速度的物理知识；</p>
</li>
<li>
<p>删除在每个prompt最前面的触发词（Missing trigger words），比如："Hints:"；</p>
</li>
<li>
<p>提供错误的模拟结果（Incorrect simulation）：比如真实模拟结果是"变快"，我们把这个模拟结果修改为"变慢"；</p>
</li>
</ul>
<p>从表4中的结果可以看出，每个prompt前面的触发词对最终结果有影响，但影响相对较小。而"答非所问"和"提供错误的模拟结果"这两种条件下的实验指标下降明显，以此说明模拟结果的存在性和正确性对推理能力是很重要的。</p>
<h4 id="few-shotminds-eye">能否用few-shot替代Mind's Eye？<a class="headerlink" href="#few-shotminds-eye" title="Permanent link">#</a></h4>
<p><img alt="" src="/006_LLM/001_PromptEngineering-MindsEye/assets/Figure3.png" /></p>
<blockquote>
<p>这个消融实验感觉设计的没有必要，已经比较公认的就是fet-shot方式只能使用模型永久记忆住的知识，而不能够更新知识。这里的Mind's Eye是融入了新的物理知识，这两个方法不具有可替代性。</p>
</blockquote>
<p>上图中有五种实验对比，其他四种都已经提到过了，说一下 Semi-Mind's Eye 是如何操作的？这个实验是也会给添加上类似 Mind's Eye 中的模拟结果类似形式的内容，但是只是形式上非常相似，关键的模拟结果信息会被去除，比如：</p>
<p><strong>模拟结果：</strong> Two baseballs take the same time to hit the ground.</p>
<p><strong>Mind's Eye：</strong> Hints: Two baseballs take the same time to hit the ground.</p>
<p><strong>Semi-Mind's Eye：</strong> Hints: Two baseballs take the time to hit the ground.</p>
<p>从图3中的结果可以看出：（1）Vanilla 与 Chain-of-Thought(few-shot)的效果都不如Mind's Eye。（2）Chain-of-Thought(few-shot)与Semi-Mind's Eye的效果存在一定的不稳定性，也就是不随着样例样本数的增加，效果稳定上升。猜测：这两种方法能否起效果，跟小样本样例中的推理过程是否与给定问题的推理过程足够类似有关。</p>
<h4 id="text-to-code">text-to-code模型能否用更小的模型？<a class="headerlink" href="#text-to-code" title="Permanent link">#</a></h4>
<p><img alt="" src="/006_LLM/001_PromptEngineering-MindsEye/assets/Table5.png" /></p>
<p>如上图所示，text-to-code模型使用两个尺寸：0.3B和1.5B。</p>
<p>从结果中可以看出，相比于1.5B的text-to-code模型，0.3B的模型会导致2%到4%的指标降低。</p>
<p>另外可以观察到如下现象：</p>
<ul>
<li>使用1.3B的GPT模型时，zero-shot和few-shot分别降低4%和3%；</li>
<li>使用175B的GPT模型时，zero-shot和few-shot分别降低3%和2%；</li>
</ul>
<p>也就是说：更大的GPT模型拥有着更多知识和更强的能力，在其外部信息降低相同程度时，性能下降的更慢一些。</p>
<h2 id="_6">相关工作<a class="headerlink" href="#_6" title="Permanent link">#</a></h2>
<p><strong>Grounded Reasoning（理性推理，不确定是否这么翻译）</strong>：目前的主要研究包括CoT、zero-shot CoT、self-Consistency等等，主要是通过"设计更好的prompt"和"优化推理过程"，这两种方式提升推理能力。</p>
<p><strong>Augmented Language Models（增强语言模型）</strong>：这个主要是给LM增加额外的知识。比如与检索结合，还有本文中提到的Minerva是将 (问题, 文档, 答案) 这种三元组做微调。</p>
<p><strong>Modeling the World（对世界建模）</strong>：类似于人会通过各种感官进行学习，和对当前事情做判断类似，对世界建模希望把各种信息都输入给模型。</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2021 Microsoft Research;<a href="https://beian.miit.gov.cn/">备案号：京ICP备2022025323号-1</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../mathjax-config.js" defer></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
