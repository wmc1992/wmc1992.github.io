<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="mingchao.wang">
        <link rel="canonical" href="https://mingchao.wang/003_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/001_%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/02_%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%8E%9F%E7%90%86/">
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>Index - 算法工程师笔记</title>
        <link href="../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/obsidian.min.css">
        <link href="../../../css/extra.css" rel="stylesheet">

        <script src="../../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-274394082');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="../../..">算法工程师笔记</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/wmc1992/" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#_1" class="nav-link">分类任务损失函数的原理</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#_2" class="nav-link">一、分类任务的符号说明</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#kl" class="nav-link">二、从KL散度推导出损失函数</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#21" class="nav-link">2.1 推导二分类的损失函数</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#22" class="nav-link">2.2 推导多分类的损失函数</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_3" class="nav-link">三、从似然函数推导出损失函数</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#31" class="nav-link">3.1 推导二分类的损失函数</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#32" class="nav-link">3.2 推导多分类的损失函数</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_4" class="nav-link">四、总结</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#reference" class="nav-link">Reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p align="right">[<a href="/KceiAVMu_no_toc/">隐藏左侧目录栏</a>][<a href="/KceiAVMu/">显示左侧目录栏</a>]</p>

<blockquote>
<p>该文章有不少的漏洞！！！</p>
<p>该文章有不少的漏洞！！！</p>
<p>该文章有不少的漏洞！！！</p>
<p>重要的事情说三遍，尽快修改该文章。</p>
</blockquote>
<h1 id="_1">分类任务损失函数的原理<a class="headerlink" href="#_1" title="Permanent link">#</a></h1>
<h2 id="_2">一、分类任务的符号说明<a class="headerlink" href="#_2" title="Permanent link">#</a></h2>
<p>这里所说的分类任务是指二分类任务和多分类任务，其他如多标签分类任务其损失函数与二分类完全相同。</p>
<p>数据集：<span class="arithmatex"><span class="MathJax_Preview">D=\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}</span><script type="math/tex">D=\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}</script></span>，其中 <span class="arithmatex"><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> 表示样本总数量。</p>
<p>类别集合：<span class="arithmatex"><span class="MathJax_Preview">C=\{class1, class2, ..., class|C|\}</span><script type="math/tex">C=\{class1, class2, ..., class|C|\}</script></span>，其中 <span class="arithmatex"><span class="MathJax_Preview">|C|</span><script type="math/tex">|C|</script></span> 表示类别总数，即这是一个几分类任务。以一个三个类别的情感分析任务为例，类别集合为：<span class="arithmatex"><span class="MathJax_Preview">C=\{正向, 负向, 中性\}</span><script type="math/tex">C=\{正向, 负向, 中性\}</script></span>，且 <span class="arithmatex"><span class="MathJax_Preview">|C|=3</span><script type="math/tex">|C|=3</script></span>；</p>
<p>对某条样本的类别做one hot编码后，得到一个只有一个元素为1，其他元素都为0的向量。还是以上述三个类别的情感分析任务为例，做one hot编码之后得到的向量可能为：<span class="arithmatex"><span class="MathJax_Preview">(1, 0, 0)</span><script type="math/tex">(1, 0, 0)</script></span>、<span class="arithmatex"><span class="MathJax_Preview">(0, 1, 0)</span><script type="math/tex">(0, 1, 0)</script></span>、<span class="arithmatex"><span class="MathJax_Preview">(0, 0, 1)</span><script type="math/tex">(0, 0, 1)</script></span>；</p>
<p>另外还有两个常见的符号为：<span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span>，其中 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 表示第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本的标注结果；<span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 表示第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本的模型预测结果；关于这两个符号更详细的含义在二分类任务和多分类任务中并不相同，在后面使用时再详细说明其含义。</p>
<p>二分类任务的损失函数为：<span class="arithmatex"><span class="MathJax_Preview">\begin{equation}L(\theta)=-\sum_{i=1}^N \big[ y_i \log(\hat{y}_i) + (1-y_i)\log (1-\hat{y}_i) \big]\end{equation}</span><script type="math/tex">\begin{equation}L(\theta)=-\sum_{i=1}^N \big[ y_i \log(\hat{y}_i) + (1-y_i)\log (1-\hat{y}_i) \big]\end{equation}</script></span></p>
<p>多分类任务的损失函数为：<span class="arithmatex"><span class="MathJax_Preview">\begin{equation}L(\theta)=-\sum_{i=1}^N y_i \log \hat{y}_i\end{equation}</span><script type="math/tex">\begin{equation}L(\theta)=-\sum_{i=1}^N y_i \log \hat{y}_i\end{equation}</script></span></p>
<p>下面要做的工作就是推导出上述两个损失函数的公式。</p>
<h2 id="kl">二、从KL散度推导出损失函数<a class="headerlink" href="#kl" title="Permanent link">#</a></h2>
<p>深度学习的目标是：希望学习的 <strong>模型分布</strong> <span class="arithmatex"><span class="MathJax_Preview">p_{model}</span><script type="math/tex">p_{model}</script></span> 与该任务的真实分布 <span class="arithmatex"><span class="MathJax_Preview">P_{real}</span><script type="math/tex">P_{real}</script></span> 一致。</p>
<p>问题在于该任务的真实分布 <span class="arithmatex"><span class="MathJax_Preview">P_{real}</span><script type="math/tex">P_{real}</script></span> 是无法获取到的，能够获取到的是 <strong>数据分布</strong> <span class="arithmatex"><span class="MathJax_Preview">P_{data}</span><script type="math/tex">P_{data}</script></span>，我们一般认为训练数据是从总体中独立同分布采样出来的，基于该条件下，就可以认为 <strong>数据分布</strong> <span class="arithmatex"><span class="MathJax_Preview">P_{data}</span><script type="math/tex">P_{data}</script></span> 与真实分布 <span class="arithmatex"><span class="MathJax_Preview">P_{real}</span><script type="math/tex">P_{real}</script></span> 是一致的。这样深度学习的目标就是：希望学到的 <strong>模型分布</strong> <span class="arithmatex"><span class="MathJax_Preview">P_{model}</span><script type="math/tex">P_{model}</script></span> 与 <strong>数据分布</strong> <span class="arithmatex"><span class="MathJax_Preview">P_{data}</span><script type="math/tex">P_{data}</script></span> 一致。</p>
<p>然后剩余的问题就是如何评估两个分布是否一致？答案是使用KL散度进行评估。因为KL散度的定义就是衡量两个概率分布 <span class="arithmatex"><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> 的差异。</p>
<p>两个分布越相近，KL散度越小；两个分布的差异越大，KL散度也越大；当两个分布相同时，KL散度为0。</p>
<p>KL散度的公式（关于KL散度的更多说明，详见<a href="/0ISjGzGG/">KL散度</a>）：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}D_{KL}(p|q)=\sum_{i=1}^N p(x_i) \log \frac{p(x_i)}{q(x_i)} = \sum_{i=1}^N \big[ p(x_i) \log p(x_i) -p(x_i) \log q(x_i) \big]\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}D_{KL}(p|q)=\sum_{i=1}^N p(x_i) \log \frac{p(x_i)}{q(x_i)} = \sum_{i=1}^N \big[ p(x_i) \log p(x_i) -p(x_i) \log q(x_i) \big]\end{equation}</script>
</div>
<p>上述公式中的 <span class="arithmatex"><span class="MathJax_Preview">p(x_i)</span><script type="math/tex">p(x_i)</script></span> 表示 <strong>数据分布</strong> ；<span class="arithmatex"><span class="MathJax_Preview">q(x_i)</span><script type="math/tex">q(x_i)</script></span> 表示 <strong>模型分布</strong> ；</p>
<p>在上述KL散度的公式中 <span class="arithmatex"><span class="MathJax_Preview">p(x_i) \log p(x_i)</span><script type="math/tex">p(x_i) \log p(x_i)</script></span> 这一项是训练集的熵，在深度学习中训练集是已知且固定的，所以其熵是一个常数，所以可以将该项省略掉。将该项省略掉之后就得到交叉熵（也称相对熵）的公式了。交叉熵也就是在分类任务中使用的损失函数，如下：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta) = -\sum_{i=1}^N p(x_i) \log q(x_i)\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta) = -\sum_{i=1}^N p(x_i) \log q(x_i)\end{equation}</script>
</div>
<h3 id="21">2.1 推导二分类的损失函数<a class="headerlink" href="#21" title="Permanent link">#</a></h3>
<p>二分类任务只有两个类别：{正, 负}，在二分类任务中 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 的含义为：</p>
<ul>
<li><span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 表示模型对第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本预测类别为"正"的概率；</li>
<li><span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 表示第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本所属类别是否为正例。如果将第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本的标签做one hot编码得到一个包含两个元素的向量，那么 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 就表示该向量中第一个元素的值，举例详细说明：<ul>
<li>若第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本所属类别为"正"，则其标签做one hot编码后的向量为 <span class="arithmatex"><span class="MathJax_Preview">(1, 0)</span><script type="math/tex">(1, 0)</script></span>，此时 <span class="arithmatex"><span class="MathJax_Preview">y_i=1</span><script type="math/tex">y_i=1</script></span>（取向量中第一个元素的值）；</li>
<li>若第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本所属类别为"负"，则其标签做one hot编码后的向量为 <span class="arithmatex"><span class="MathJax_Preview">(0, 1)</span><script type="math/tex">(0, 1)</script></span>，此时 <span class="arithmatex"><span class="MathJax_Preview">y_i=0</span><script type="math/tex">y_i=0</script></span>（取向量中第一个元素的值）；</li>
</ul>
</li>
</ul>
<p>交叉熵公式（2）中的 <span class="arithmatex"><span class="MathJax_Preview">p(x_i)</span><script type="math/tex">p(x_i)</script></span> 表示数据分布，即 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 或 <span class="arithmatex"><span class="MathJax_Preview">(1-y_i)</span><script type="math/tex">(1-y_i)</script></span>；<span class="arithmatex"><span class="MathJax_Preview">q(x_i)</span><script type="math/tex">q(x_i)</script></span> 表示模型分布，即<span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 或 <span class="arithmatex"><span class="MathJax_Preview">(1-\hat{y}_i)</span><script type="math/tex">(1-\hat{y}_i)</script></span>。这样就很容易将交叉熵公式使用 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 进行表示，即下述两个公式：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta)=\sum_{i=1}^Nl_i(\theta)\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta)=\sum_{i=1}^Nl_i(\theta)\end{equation}</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}
l_i(\theta)=\begin{cases}
-y_i \log \hat{y}_i, &amp;\text{当}y_i=1\text{时}\\
-(1-y_i) \log (1-\hat{y}_i), &amp;\text{当}y_i=0\text{时}
\end{cases}
\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}
l_i(\theta)=\begin{cases}
-y_i \log \hat{y}_i, &\text{当}y_i=1\text{时}\\
-(1-y_i) \log (1-\hat{y}_i), &\text{当}y_i=0\text{时}
\end{cases}
\end{equation}</script>
</div>
<p>上述公式是分段形式的，还可以将其合并为一个函数，就得到了二分类任务的损失函数：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta)=-\sum_{i=1}^N \big[ y_i \log(\hat{y}_i) + (1-y_i)\log (1-\hat{y}_i) \big]\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta)=-\sum_{i=1}^N \big[ y_i \log(\hat{y}_i) + (1-y_i)\log (1-\hat{y}_i) \big]\end{equation}</script>
</div>
<h3 id="22">2.2 推导多分类的损失函数<a class="headerlink" href="#22" title="Permanent link">#</a></h3>
<p>对于多分类任务要先说明一下 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 的含义，在多分类中这两个符号的含义与二分类中是不同的，这也是理解二分类和多分类的损失函数时的一个小坑：</p>
<ul>
<li><span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 表示模型对第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本所属类别预测的概率；</li>
<li><span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 表示第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本的标签做one hot编码后得到的向量中，该样本所属类别的在向量中的值，也就是恒为1；</li>
</ul>
<p>还是以三分类任务 {正向, 负向, 中性} 进行举例说明：</p>
<ul>
<li>
<p>若第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本所属类别为"正向"，则其标签做one hot编码后的向量为 <span class="arithmatex"><span class="MathJax_Preview">(1, 0, 0)</span><script type="math/tex">(1, 0, 0)</script></span>，此时 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 表示的是该向量中的第一个元素，即<span class="arithmatex"><span class="MathJax_Preview">y_i=1</span><script type="math/tex">y_i=1</script></span>（<span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span>取值永远为1）；此时 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 表示的是模型对第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本预测为"正向"的概率，假设此时模型对三个类别预测的概率为 <span class="arithmatex"><span class="MathJax_Preview">(0.2, 0.3, 0.5)</span><script type="math/tex">(0.2, 0.3, 0.5)</script></span>，则 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i=0.2</span><script type="math/tex">\hat{y}_i=0.2</script></span>；</p>
</li>
<li>
<p>若第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本所属类别为"负向"，则其标签做one hot编码后的向量为 <span class="arithmatex"><span class="MathJax_Preview">(0, 1, 0)</span><script type="math/tex">(0, 1, 0)</script></span>，此时 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 表示的是该向量中的第二个元素，即<span class="arithmatex"><span class="MathJax_Preview">y_i=1</span><script type="math/tex">y_i=1</script></span>（<span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span>取值永远为1）；此时 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 表示的是模型对第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本预测为"负向"的概率，假设此时模型对三个类别预测的概率为 <span class="arithmatex"><span class="MathJax_Preview">(0.2, 0.3, 0.5)</span><script type="math/tex">(0.2, 0.3, 0.5)</script></span>，则 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i=0.3</span><script type="math/tex">\hat{y}_i=0.3</script></span>；</p>
</li>
<li>
<p>若第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本所属类别为"中性"，则其标签做one hot编码后的向量为 <span class="arithmatex"><span class="MathJax_Preview">(0, 0, 1)</span><script type="math/tex">(0, 0, 1)</script></span>，此时 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 表示的是该向量中的第三个元素，即<span class="arithmatex"><span class="MathJax_Preview">y_i=1</span><script type="math/tex">y_i=1</script></span>（<span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span>取值永远为1）；此时 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 表示的是模型对第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本预测为"中性"的概率，假设此时模型对三个类别预测的概率为 <span class="arithmatex"><span class="MathJax_Preview">(0.2, 0.3, 0.5)</span><script type="math/tex">(0.2, 0.3, 0.5)</script></span>，则 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i=0.5</span><script type="math/tex">\hat{y}_i=0.5</script></span>；</p>
</li>
</ul>
<p>交叉熵公式（2）中的 <span class="arithmatex"><span class="MathJax_Preview">p(x_i)</span><script type="math/tex">p(x_i)</script></span> 表示数据分布，即 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span>；<span class="arithmatex"><span class="MathJax_Preview">q(x_i)</span><script type="math/tex">q(x_i)</script></span> 表示模型分布，即<span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span>。这样就很容易将交叉熵公式使用 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 进行表示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta)=-\sum_{i=1}^N y_i \log \hat{y}_i\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta)=-\sum_{i=1}^N y_i \log \hat{y}_i\end{equation}</script>
</div>
<p>由于 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 恒为1，所以可以将其省略，就得到了多分类任务的损失函数：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta)=-\sum_{i=1}^N \log \hat{y}_i\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta)=-\sum_{i=1}^N \log \hat{y}_i\end{equation}</script>
</div>
<p><strong>综上可以看出：</strong> 二分类和多分类的交叉熵损失的公式，之所以在形式上看起来不一致，主要是因为符号 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 所表示的含义不同。虽然二分类和多分类交叉熵损失的公式在形式上看起来不同，但是从推导过上可知它们的本质是相同的，只不过是符号定义上有差别。</p>
<h2 id="_3">三、从似然函数推导出损失函数<a class="headerlink" href="#_3" title="Permanent link">#</a></h2>
<blockquote>
<p>该小节中的符号 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 与 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 的含义与上一小节是完全相同的。</p>
</blockquote>
<p>从极大化似然函数的角度出发，我们希望极大化如下似然函数。</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}\text{Likelihood} = \log \prod_{i=1}^N p(x_i) = \sum_{i=1}^N \log p(x_i)\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}\text{Likelihood} = \log \prod_{i=1}^N p(x_i) = \sum_{i=1}^N \log p(x_i)\end{equation}</script>
</div>
<p>将极大化任务改为极小化任务只需加一个负号即可，得到损失函数如下：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta) = -\sum_{i=1}^N \log p(x_i)\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta) = -\sum_{i=1}^N \log p(x_i)\end{equation}</script>
</div>
<p>公式中的符号 <span class="arithmatex"><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> 表示样本总数。<span class="arithmatex"><span class="MathJax_Preview">p(x_i)</span><script type="math/tex">p(x_i)</script></span> 表示模型对第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本，将其预测为其所属类别的概率。</p>
<h3 id="31">3.1 推导二分类的损失函数<a class="headerlink" href="#31" title="Permanent link">#</a></h3>
<p>在二分类任务中：</p>
<ul>
<li>当第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本类别为"正"时，<span class="arithmatex"><span class="MathJax_Preview">y_i=1</span><script type="math/tex">y_i=1</script></span>，模型对该样本属于"正"类别的概率为 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span>；</li>
<li>当第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本类别为"负"时，<span class="arithmatex"><span class="MathJax_Preview">y_i=0</span><script type="math/tex">y_i=0</script></span>，模型对该样本属于"负"类别的概率为 <span class="arithmatex"><span class="MathJax_Preview">1-\hat{y}_i</span><script type="math/tex">1-\hat{y}_i</script></span>；</li>
</ul>
<p>将公式（9）改为使用 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 进行表示：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta)=\sum_{i=1}^Nl_i(\theta)\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta)=\sum_{i=1}^Nl_i(\theta)\end{equation}</script>
</div>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}
l_i(\theta)=\begin{cases}
-\log \hat{y}_i, &amp;\text{当}y_i=1\text{时}\\
-\log (1-\hat{y}_i), &amp;\text{当}y_i=0\text{时}
\end{cases}
\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}
l_i(\theta)=\begin{cases}
-\log \hat{y}_i, &\text{当}y_i=1\text{时}\\
-\log (1-\hat{y}_i), &\text{当}y_i=0\text{时}
\end{cases}
\end{equation}</script>
</div>
<p>上述公式是分段形式的，还可以将其合并为一个函数，就得到了二分类任务的损失函数：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta)=-\sum_{i=1}^N \big[ y_i \log(\hat{y}_i) + (1-y_i)\log (1-\hat{y}_i) \big]\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta)=-\sum_{i=1}^N \big[ y_i \log(\hat{y}_i) + (1-y_i)\log (1-\hat{y}_i) \big]\end{equation}</script>
</div>
<h3 id="32">3.2 推导多分类的损失函数<a class="headerlink" href="#32" title="Permanent link">#</a></h3>
<p>在多分类任务中，类别集合为 <span class="arithmatex"><span class="MathJax_Preview">C=\{class1, class2, ..., class|C|\}</span><script type="math/tex">C=\{class1, class2, ..., class|C|\}</script></span>，类别总数为 <span class="arithmatex"><span class="MathJax_Preview">|C|</span><script type="math/tex">|C|</script></span>；</p>
<p>对于第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 条样本，模型将其预测为所属类别的概率为 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span>；</p>
<p>从公式（9）中来看，与 <span class="arithmatex"><span class="MathJax_Preview">y_i</span><script type="math/tex">y_i</script></span> 没什么关系，将其改为使用 <span class="arithmatex"><span class="MathJax_Preview">\hat{y}_i</span><script type="math/tex">\hat{y}_i</script></span> 表示的形式，就得到了多分类任务的损失函数：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{equation}L(\theta)=-\sum_{i=1}^N \log \hat{y}_i\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}L(\theta)=-\sum_{i=1}^N \log \hat{y}_i\end{equation}</script>
</div>
<p><strong>综上可以看出：</strong> 从似然函数出发推导出的二分类和多分类的损失函数与从KL散度出发推导出的损失函数是完全相同的。</p>
<h2 id="_4">四、总结<a class="headerlink" href="#_4" title="Permanent link">#</a></h2>
<p>本文分别从KL散度和似然函数的角度出发，推导出了二分类任务和多分类任务的损失函数。从上述两个角度出发推导出的结果都是相同的。至于为什么最终推导出的结果相同，KL散度与似然函数之间是否有关系，受限于数学基础不足，还不清楚。本人一般在对二分类和多分类任务的损失函数进行思考时，多是从KL散度的角度出发的，即衡量模型分布<span class="arithmatex"><span class="MathJax_Preview">P_{model}</span><script type="math/tex">P_{model}</script></span>与数据分布<span class="arithmatex"><span class="MathJax_Preview">P_{data}</span><script type="math/tex">P_{data}</script></span>是否足够相似。</p>
<h2 id="reference">Reference<a class="headerlink" href="#reference" title="Permanent link">#</a></h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/74073096">https://zhuanlan.zhihu.com/p/74073096</a></li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2021 Microsoft Research;<a href="https://beian.miit.gov.cn/">备案号：京ICP备2022025323号-1</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js" defer></script>
        <script src="../../../mathjax-config.js" defer></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
        <script src="../../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
